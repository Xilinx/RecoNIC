diff --git a/Makefile b/Makefile
index b8a3f57..130c765 100644
--- a/Makefile
+++ b/Makefile
@@ -5,8 +5,7 @@ ONIC_DRV_KVER := $(shell uname -r)
 SRC_FOLDERS = . libqdma/qdma_access libqdma \
               libqdma/qdma_access/qdma_soft_access \
               libqdma/qdma_access/eqdma_soft_access \
-              libqdma/qdma_access/qdma_s80_hard_access \
-			  jsmn 
+              libqdma/qdma_access/qdma_s80_hard_access
 
 ifneq ($(SUBDIRS),)
     ONIC_OBJS = $(foreach CURR, $(SRC_FOLDERS), $(patsubst $(SUBDIRS)/$(CURR)/%.c, $(CURR)/%.o, $(wildcard $(SUBDIRS)/$(CURR)/*.c)))
@@ -32,6 +31,6 @@ install:
 	install -d ${MODULES_INSTALL_PATH}
 	install -t ${MODULES_INSTALL_PATH} $(MOD_NAME).ko
 
-json_install:
-	install -d /lib/firmware/xilinx/
-	install -m 644 json/*.json /lib/firmware/xilinx/
+#json_install:
+#	install -d /lib/firmware/xilinx/
+#	install -m 644 json/*.json /lib/firmware/xilinx/
diff --git a/README.md b/README.md
index a52daa2..f3327ce 100644
--- a/README.md
+++ b/README.md
@@ -1,102 +1,24 @@
 # onic-driver
 
-onic-driver is the brand-new driver for [open-nic-shell](https://github.com/Xilinx/open-nic-shell).
-It is written refering to [qep-driver](https://github.com/Xilinx/qep-drivers/tree/master/linux-kernel/driver)
-based on [libqdma](https://github.com/Xilinx/dma_ip_drivers/tree/master/QDMA/linux-kernel/driver/libqdma)<br>
-Because libqdma has the full-blown functions for qdma, we can treat it in high level in the application driver.<br>
+**[onic-driver](https://github.com/Hyunok-Kim/onic-driver)** is yet another open-source driver developed by [Hyunok Kim](https://github.com/Hyunok-Kim) for the AMD [OpenNIC shell](https://github.com/Xilinx/open-nic-shell), adapted from AMD [QDMA Ethernet Platform (QEP) driver](https://github.com/Xilinx/qep-drivers) and [OpenNIC driver](https://github.com/Xilinx/open-nic-driver).
 
-However, two modifications are required.
-1. [open-nic-shell patch](https://github.com/Hyunok-Kim/open-nic-shell/commit/a1ba78308efded589967431eddf0a397f69f2806)
-2. [libqdma patch](https://github.com/Hyunok-Kim/dma_ip_drivers/commit/a6c6e41243a2eecc66f6e157f93017b8aa4941e2)(The patch is applied to this driver)
+Compared to [OpenNIC driver](https://github.com/Xilinx/open-nic-driver), **onic-driver** provides improved support for various QDMA features. This enhanced support is achieved by the [QEP driver](https://github.com/Xilinx/qep-drivers), which is built upon AMD [libqdma](https://github.com/Xilinx/dma_ip_drivers/tree/master/QDMA/linux-kernel/driver/libqdma).
 
-The first patch is required because libqdma require the specific data formats for st h2c descriptor and st c2h completion entry.<br>
-The second patch is to fix the problem the irq allocation order of original libqdma issues the abnormal user/error interrupts 
+**RecoNIC** (<ins>R</ins>DMA-<ins>e</ins>nabled <ins>C</ins>ompute <ins>O</ins>ffloading on Smart<ins>NIC</ins>) leverages onic-driver as its software networking stack. Moreover, **RecoNIC** extends onic-driver to support data copy between host and device's memory over PCIe.
 
-## JSON Configuration
+## How to use
 
-Instead of module parameters, json files are used to configure driver settings.
-Each `pf` has it's own json file under `json` directory. 
-
-* `queue_base` and `queue_max` are used to restrict the range of queues for each `pf`.
-* `used_queues` is the real number of used queues. The value of `0` means that the number equals that of data interrupts.
-* In the only one of `pf`s, `pci_master_pf` should be `true`. In the others, the value should be `false`.
-* It runs on direct interrupt mode when `poll_mode` is `false`. Otherwise, it runs on poll mode.
-* RS-FEC of cmac is enabled when `rsfec_en` is `true`.
-* `port_id` is used for cmac id and pf id.
-* Each `pf` must have a unique `mac_addr`.
-
-For installation,
-```sh
-$ sudo make json_install
+* compile and load the kernel module
 ```
-
-## Test Setup
-
-The following test setup is valid for a machine which has an alveo card with two QSF28 ports.
-One port is plugged directly into the other. 
-`open-nic-shell` project should be built with the option of `-num_cmac_port 2`
-
-* ip setting
-```sh
-$ sudo ip netns add ns_enp2s0f0
-$ sudo ip netns add ns_enp2s0f1
-$ sudo ip link set enp2s0f0 netns ns_enp2s0f0
-$ sudo ip netns exec ns_enp2s0f0 ip addr add dev enp2s0f0 192.168.253.1/24
-$ sudo ip netns exec ns_enp2s0f0 ip link set dev enp2s0f0 up
-$ sudo ip link set enp2s0f1 netns ns_enp2s0f1
-$ sudo ip netns exec ns_enp2s0f1 ip addr add dev enp2s0f1 192.168.253.2/24
-$ sudo ip netns exec ns_enp2s0f1 ip link set dev enp2s0f1 up
+$ make
+$ sudo insmod onic.ko
 ```
 
-* iperf server
-```sh
-$ sudo ip netns exec ns_enp2s0f0 iperf -s -P8
-------------------------------------------------------------
-Server listening on TCP port 5001
-TCP window size:  128 KByte (default)
-------------------------------------------------------------
-[  4] local 192.168.253.1 port 5001 connected with 192.168.253.2 port 45060
-[  5] local 192.168.253.1 port 5001 connected with 192.168.253.2 port 45056
-[  6] local 192.168.253.1 port 5001 connected with 192.168.253.2 port 45058
-[  7] local 192.168.253.1 port 5001 connected with 192.168.253.2 port 45054
-[  8] local 192.168.253.1 port 5001 connected with 192.168.253.2 port 45052
-[ 10] local 192.168.253.1 port 5001 connected with 192.168.253.2 port 45064
-[ 12] local 192.168.253.1 port 5001 connected with 192.168.253.2 port 45066
-[ 11] local 192.168.253.1 port 5001 connected with 192.168.253.2 port 45062
-[ ID] Interval       Transfer     Bandwidth
-[  7]  0.0-10.0 sec  4.17 GBytes  3.58 Gbits/sec
-[ 11]  0.0-10.0 sec  2.50 GBytes  2.15 Gbits/sec
-[  4]  0.0-10.0 sec   765 MBytes   640 Mbits/sec
-[  5]  0.0-10.0 sec   506 MBytes   423 Mbits/sec
-[  6]  0.0-10.0 sec   844 MBytes   707 Mbits/sec
-[  8]  0.0-10.0 sec   833 MBytes   697 Mbits/sec
-[ 10]  0.0-10.0 sec   512 MBytes   429 Mbits/sec
-[ 12]  0.0-10.0 sec   364 MBytes   304 Mbits/sec
+* remove the kernel module
 ```
-
-* iperf client
-```sh
-$ sudo ip netns exec ns_enp2s0f1 iperf -c 192.168.253.1 -P8
-------------------------------------------------------------
-Client connecting to 192.168.253.1, TCP port 5001
-TCP window size:  264 KByte (default)
-------------------------------------------------------------
-[ 10] local 192.168.253.2 port 45066 connected with 192.168.253.1 port 5001
-[  8] local 192.168.253.2 port 45062 connected with 192.168.253.1 port 5001
-[  9] local 192.168.253.2 port 45064 connected with 192.168.253.1 port 5001
-[  3] local 192.168.253.2 port 45052 connected with 192.168.253.1 port 5001
-[  6] local 192.168.253.2 port 45056 connected with 192.168.253.1 port 5001
-[  5] local 192.168.253.2 port 45058 connected with 192.168.253.1 port 5001
-[  7] local 192.168.253.2 port 45060 connected with 192.168.253.1 port 5001
-[  4] local 192.168.253.2 port 45054 connected with 192.168.253.1 port 5001
-[ ID] Interval       Transfer     Bandwidth
-[  8]  0.0-10.0 sec  2.50 GBytes  2.15 Gbits/sec
-[  4]  0.0-10.0 sec  4.17 GBytes  3.59 Gbits/sec
-[ 10]  0.0-10.0 sec   364 MBytes   305 Mbits/sec
-[  9]  0.0-10.0 sec   512 MBytes   429 Mbits/sec
-[  3]  0.0-10.0 sec   833 MBytes   698 Mbits/sec
-[  6]  0.0-10.0 sec   506 MBytes   424 Mbits/sec
-[  5]  0.0-10.0 sec   844 MBytes   708 Mbits/sec
-[  7]  0.0-10.0 sec   765 MBytes   641 Mbits/sec
-[SUM]  0.0-10.0 sec  10.4 GBytes  8.93 Gbits/sec
+$ sudo rmmod onic
 ```
+
+## How to test data copy feature
+
+Please refer to RecoNIC's README file.
\ No newline at end of file
diff --git a/jsmn/jsmn.c b/jsmn/jsmn.c
deleted file mode 100644
index 853c3f1..0000000
--- a/jsmn/jsmn.c
+++ /dev/null
@@ -1,314 +0,0 @@
-#include "jsmn.h"
-
-/**
- * Allocates a fresh unused token from the token pool.
- */
-static jsmntok_t *jsmn_alloc_token(jsmn_parser *parser,
-		jsmntok_t *tokens, size_t num_tokens) {
-	jsmntok_t *tok;
-	if (parser->toknext >= num_tokens) {
-		return NULL;
-	}
-	tok = &tokens[parser->toknext++];
-	tok->start = tok->end = -1;
-	tok->size = 0;
-#ifdef JSMN_PARENT_LINKS
-	tok->parent = -1;
-#endif
-	return tok;
-}
-
-/**
- * Fills token type and boundaries.
- */
-static void jsmn_fill_token(jsmntok_t *token, jsmntype_t type,
-                            int start, int end) {
-	token->type = type;
-	token->start = start;
-	token->end = end;
-	token->size = 0;
-}
-
-/**
- * Fills next available token with JSON primitive.
- */
-static int jsmn_parse_primitive(jsmn_parser *parser, const char *js,
-		size_t len, jsmntok_t *tokens, size_t num_tokens) {
-	jsmntok_t *token;
-	int start;
-
-	start = parser->pos;
-
-	for (; parser->pos < len && js[parser->pos] != '\0'; parser->pos++) {
-		switch (js[parser->pos]) {
-#ifndef JSMN_STRICT
-			/* In strict mode primitive must be followed by "," or "}" or "]" */
-			case ':':
-#endif
-			case '\t' : case '\r' : case '\n' : case ' ' :
-			case ','  : case ']'  : case '}' :
-				goto found;
-		}
-		if (js[parser->pos] < 32 || js[parser->pos] >= 127) {
-			parser->pos = start;
-			return JSMN_ERROR_INVAL;
-		}
-	}
-#ifdef JSMN_STRICT
-	/* In strict mode primitive must be followed by a comma/object/array */
-	parser->pos = start;
-	return JSMN_ERROR_PART;
-#endif
-
-found:
-	if (tokens == NULL) {
-		parser->pos--;
-		return 0;
-	}
-	token = jsmn_alloc_token(parser, tokens, num_tokens);
-	if (token == NULL) {
-		parser->pos = start;
-		return JSMN_ERROR_NOMEM;
-	}
-	jsmn_fill_token(token, JSMN_PRIMITIVE, start, parser->pos);
-#ifdef JSMN_PARENT_LINKS
-	token->parent = parser->toksuper;
-#endif
-	parser->pos--;
-	return 0;
-}
-
-/**
- * Fills next token with JSON string.
- */
-static int jsmn_parse_string(jsmn_parser *parser, const char *js,
-		size_t len, jsmntok_t *tokens, size_t num_tokens) {
-	jsmntok_t *token;
-
-	int start = parser->pos;
-
-	parser->pos++;
-
-	/* Skip starting quote */
-	for (; parser->pos < len && js[parser->pos] != '\0'; parser->pos++) {
-		char c = js[parser->pos];
-
-		/* Quote: end of string */
-		if (c == '\"') {
-			if (tokens == NULL) {
-				return 0;
-			}
-			token = jsmn_alloc_token(parser, tokens, num_tokens);
-			if (token == NULL) {
-				parser->pos = start;
-				return JSMN_ERROR_NOMEM;
-			}
-			jsmn_fill_token(token, JSMN_STRING, start+1, parser->pos);
-#ifdef JSMN_PARENT_LINKS
-			token->parent = parser->toksuper;
-#endif
-			return 0;
-		}
-
-		/* Backslash: Quoted symbol expected */
-		if (c == '\\' && parser->pos + 1 < len) {
-			int i;
-			parser->pos++;
-			switch (js[parser->pos]) {
-				/* Allowed escaped symbols */
-				case '\"': case '/' : case '\\' : case 'b' :
-				case 'f' : case 'r' : case 'n'  : case 't' :
-					break;
-				/* Allows escaped symbol \uXXXX */
-				case 'u':
-					parser->pos++;
-					for(i = 0; i < 4 && parser->pos < len && js[parser->pos] != '\0'; i++) {
-						/* If it isn't a hex character we have an error */
-						if(!((js[parser->pos] >= 48 && js[parser->pos] <= 57) || /* 0-9 */
-									(js[parser->pos] >= 65 && js[parser->pos] <= 70) || /* A-F */
-									(js[parser->pos] >= 97 && js[parser->pos] <= 102))) { /* a-f */
-							parser->pos = start;
-							return JSMN_ERROR_INVAL;
-						}
-						parser->pos++;
-					}
-					parser->pos--;
-					break;
-				/* Unexpected symbol */
-				default:
-					parser->pos = start;
-					return JSMN_ERROR_INVAL;
-			}
-		}
-	}
-	parser->pos = start;
-	return JSMN_ERROR_PART;
-}
-
-/**
- * Parse JSON string and fill tokens.
- */
-int jsmn_parse(jsmn_parser *parser, const char *js, size_t len,
-		jsmntok_t *tokens, unsigned int num_tokens) {
-	int r;
-	int i;
-	jsmntok_t *token;
-	int count = parser->toknext;
-
-	for (; parser->pos < len && js[parser->pos] != '\0'; parser->pos++) {
-		char c;
-		jsmntype_t type;
-
-		c = js[parser->pos];
-		switch (c) {
-			case '{': case '[':
-				count++;
-				if (tokens == NULL) {
-					break;
-				}
-				token = jsmn_alloc_token(parser, tokens, num_tokens);
-				if (token == NULL)
-					return JSMN_ERROR_NOMEM;
-				if (parser->toksuper != -1) {
-					tokens[parser->toksuper].size++;
-#ifdef JSMN_PARENT_LINKS
-					token->parent = parser->toksuper;
-#endif
-				}
-				token->type = (c == '{' ? JSMN_OBJECT : JSMN_ARRAY);
-				token->start = parser->pos;
-				parser->toksuper = parser->toknext - 1;
-				break;
-			case '}': case ']':
-				if (tokens == NULL)
-					break;
-				type = (c == '}' ? JSMN_OBJECT : JSMN_ARRAY);
-#ifdef JSMN_PARENT_LINKS
-				if (parser->toknext < 1) {
-					return JSMN_ERROR_INVAL;
-				}
-				token = &tokens[parser->toknext - 1];
-				for (;;) {
-					if (token->start != -1 && token->end == -1) {
-						if (token->type != type) {
-							return JSMN_ERROR_INVAL;
-						}
-						token->end = parser->pos + 1;
-						parser->toksuper = token->parent;
-						break;
-					}
-					if (token->parent == -1) {
-						if(token->type != type || parser->toksuper == -1) {
-							return JSMN_ERROR_INVAL;
-						}
-						break;
-					}
-					token = &tokens[token->parent];
-				}
-#else
-				for (i = parser->toknext - 1; i >= 0; i--) {
-					token = &tokens[i];
-					if (token->start != -1 && token->end == -1) {
-						if (token->type != type) {
-							return JSMN_ERROR_INVAL;
-						}
-						parser->toksuper = -1;
-						token->end = parser->pos + 1;
-						break;
-					}
-				}
-				/* Error if unmatched closing bracket */
-				if (i == -1) return JSMN_ERROR_INVAL;
-				for (; i >= 0; i--) {
-					token = &tokens[i];
-					if (token->start != -1 && token->end == -1) {
-						parser->toksuper = i;
-						break;
-					}
-				}
-#endif
-				break;
-			case '\"':
-				r = jsmn_parse_string(parser, js, len, tokens, num_tokens);
-				if (r < 0) return r;
-				count++;
-				if (parser->toksuper != -1 && tokens != NULL)
-					tokens[parser->toksuper].size++;
-				break;
-			case '\t' : case '\r' : case '\n' : case ' ':
-				break;
-			case ':':
-				parser->toksuper = parser->toknext - 1;
-				break;
-			case ',':
-				if (tokens != NULL && parser->toksuper != -1 &&
-						tokens[parser->toksuper].type != JSMN_ARRAY &&
-						tokens[parser->toksuper].type != JSMN_OBJECT) {
-#ifdef JSMN_PARENT_LINKS
-					parser->toksuper = tokens[parser->toksuper].parent;
-#else
-					for (i = parser->toknext - 1; i >= 0; i--) {
-						if (tokens[i].type == JSMN_ARRAY || tokens[i].type == JSMN_OBJECT) {
-							if (tokens[i].start != -1 && tokens[i].end == -1) {
-								parser->toksuper = i;
-								break;
-							}
-						}
-					}
-#endif
-				}
-				break;
-#ifdef JSMN_STRICT
-			/* In strict mode primitives are: numbers and booleans */
-			case '-': case '0': case '1' : case '2': case '3' : case '4':
-			case '5': case '6': case '7' : case '8': case '9':
-			case 't': case 'f': case 'n' :
-				/* And they must not be keys of the object */
-				if (tokens != NULL && parser->toksuper != -1) {
-					jsmntok_t *t = &tokens[parser->toksuper];
-					if (t->type == JSMN_OBJECT ||
-							(t->type == JSMN_STRING && t->size != 0)) {
-						return JSMN_ERROR_INVAL;
-					}
-				}
-#else
-			/* In non-strict mode every unquoted value is a primitive */
-			default:
-#endif
-				r = jsmn_parse_primitive(parser, js, len, tokens, num_tokens);
-				if (r < 0) return r;
-				count++;
-				if (parser->toksuper != -1 && tokens != NULL)
-					tokens[parser->toksuper].size++;
-				break;
-
-#ifdef JSMN_STRICT
-			/* Unexpected char in strict mode */
-			default:
-				return JSMN_ERROR_INVAL;
-#endif
-		}
-	}
-
-	if (tokens != NULL) {
-		for (i = parser->toknext - 1; i >= 0; i--) {
-			/* Unmatched opened object or array */
-			if (tokens[i].start != -1 && tokens[i].end == -1) {
-				return JSMN_ERROR_PART;
-			}
-		}
-	}
-
-	return count;
-}
-
-/**
- * Creates a new parser based over a given  buffer with an array of tokens
- * available.
- */
-void jsmn_init(jsmn_parser *parser) {
-	parser->pos = 0;
-	parser->toknext = 0;
-	parser->toksuper = -1;
-}
-
diff --git a/jsmn/jsmn.h b/jsmn/jsmn.h
deleted file mode 100644
index 5a5200e..0000000
--- a/jsmn/jsmn.h
+++ /dev/null
@@ -1,76 +0,0 @@
-#ifndef __JSMN_H_
-#define __JSMN_H_
-
-#include <stddef.h>
-
-#ifdef __cplusplus
-extern "C" {
-#endif
-
-/**
- * JSON type identifier. Basic types are:
- * 	o Object
- * 	o Array
- * 	o String
- * 	o Other primitive: number, boolean (true/false) or null
- */
-typedef enum {
-	JSMN_UNDEFINED = 0,
-	JSMN_OBJECT = 1,
-	JSMN_ARRAY = 2,
-	JSMN_STRING = 3,
-	JSMN_PRIMITIVE = 4
-} jsmntype_t;
-
-enum jsmnerr {
-	/* Not enough tokens were provided */
-	JSMN_ERROR_NOMEM = -1,
-	/* Invalid character inside JSON string */
-	JSMN_ERROR_INVAL = -2,
-	/* The string is not a full JSON packet, more bytes expected */
-	JSMN_ERROR_PART = -3
-};
-
-/**
- * JSON token description.
- * type		type (object, array, string etc.)
- * start	start position in JSON data string
- * end		end position in JSON data string
- */
-typedef struct {
-	jsmntype_t type;
-	int start;
-	int end;
-	int size;
-#ifdef JSMN_PARENT_LINKS
-	int parent;
-#endif
-} jsmntok_t;
-
-/**
- * JSON parser. Contains an array of token blocks available. Also stores
- * the string being parsed now and current position in that string
- */
-typedef struct {
-	unsigned int pos; /* offset in the JSON string */
-	unsigned int toknext; /* next token to allocate */
-	int toksuper; /* superior token node, e.g parent object or array */
-} jsmn_parser;
-
-/**
- * Create JSON parser over an array of tokens
- */
-void jsmn_init(jsmn_parser *parser);
-
-/**
- * Run JSON parser. It parses a JSON data string into and array of tokens, each describing
- * a single JSON object.
- */
-int jsmn_parse(jsmn_parser *parser, const char *js, size_t len,
-		jsmntok_t *tokens, unsigned int num_tokens);
-
-#ifdef __cplusplus
-}
-#endif
-
-#endif /* __JSMN_H_ */
diff --git a/json/onic_903f.json b/json/onic_903f.json
deleted file mode 100644
index feb098a..0000000
--- a/json/onic_903f.json
+++ /dev/null
@@ -1,18 +0,0 @@
-{
-	"qdma_bar": 0,
-	"user_bar": 2,
-	"queue_base": 0,
-	"queue_max": 64,
-	"used_queues": 0,
-	"pci_msix_user_cnt": 1,
-	"pci_master_pf": true,
-	"poll_mode": false,
-	"intr_mod_en": true,
-	"ring_sz": 1024,
-	"c2h_tmr_cnt": 5,
-	"c2h_cnt_thr": 64,
-	"c2h_buf_sz": 4096,
-	"rsfec_en": false,
-	"port_id": 0,
-	"mac_addr": [0x00, 0x0A, 0x35, 0x00, 0x90, 0x3F]
-}
diff --git a/json/onic_913f.json b/json/onic_913f.json
deleted file mode 100644
index 7c92dae..0000000
--- a/json/onic_913f.json
+++ /dev/null
@@ -1,18 +0,0 @@
-{
-	"qdma_bar": 0,
-	"user_bar": 2,
-	"queue_base": 64,
-	"queue_max": 64,
-	"used_queues": 0,
-	"pci_msix_user_cnt": 1,
-	"pci_master_pf": false,
-	"poll_mode": false,
-	"intr_mod_en": true,
-	"ring_sz": 1024,
-	"c2h_tmr_cnt": 5,
-	"c2h_cnt_thr": 64,
-	"c2h_buf_sz": 4096,
-	"rsfec_en": false,
-	"port_id": 1,
-	"mac_addr": [0x00, 0x0A, 0x35, 0x00, 0x91, 0x3F]
-}
diff --git a/libqdma/libqdma_export.c b/libqdma/libqdma_export.c
index 25e735c..d88d7c9 100644
--- a/libqdma/libqdma_export.c
+++ b/libqdma/libqdma_export.c
@@ -2301,8 +2301,12 @@ void sgl_unmap(struct pci_dev *pdev, struct qdma_sw_sg *sg, unsigned int sgcnt,
 		if (!sg->pg)
 			break;
 		if (sg->dma_addr) {
+#if LINUX_VERSION_CODE < KERNEL_VERSION(5, 18, 0)
 			pci_unmap_page(pdev, sg->dma_addr - sg->offset,
 							PAGE_SIZE, dir);
+#else // LINUX_VERSION_CODE >= KERNEL_VERSION(5, 18, 0)
+			dma_unmap_page(&pdev->dev, sg->dma_addr - sg->offset, PAGE_SIZE, dir);
+#endif
 			sg->dma_addr = 0UL;
 		}
 	}
@@ -2333,6 +2337,7 @@ int sgl_map(struct pci_dev *pdev, struct qdma_sw_sg *sgl, unsigned int sgcnt,
 	 */
 	for (i = 0; i < sgcnt; i++, sg++) {
 		/* !! TODO  page size !! */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(5, 18, 0)
 		sg->dma_addr = pci_map_page(pdev, sg->pg, 0, PAGE_SIZE, dir);
 		if (unlikely(pci_dma_mapping_error(pdev, sg->dma_addr))) {
 			pr_err("map sgl failed, sg %d, %u.\n", i, sg->len);
@@ -2340,6 +2345,15 @@ int sgl_map(struct pci_dev *pdev, struct qdma_sw_sg *sgl, unsigned int sgcnt,
 				sgl_unmap(pdev, sgl, i, dir);
 			return -EIO;
 		}
+#else // LINUX_VERSION_CODE >= KERNEL_VERSION(5, 18, 0)
+		sg->dma_addr = dma_map_page(&pdev->dev, sg->pg, 0, PAGE_SIZE, dir);
+		if (unlikely(dma_mapping_error(&pdev->dev, sg->dma_addr))) {
+			pr_err("map sgl failed, sg %d, %u.\n", i, sg->len);
+			if (i)
+				sgl_unmap(pdev, sgl, i, dir);
+			return -EIO;
+		}
+#endif
 		sg->dma_addr += sg->offset;
 	}
 
@@ -2415,8 +2429,8 @@ ssize_t qdma_request_submit(unsigned long dev_hndl, unsigned long id,
 	 */
 	if ((req->write && (descq->conf.q_type != Q_H2C)) ||
 	    (!req->write && (descq->conf.q_type != Q_C2H))) {
-		pr_err("%s: bad direction, %c.\n",
-			descq->conf.name, req->write ? 'W' : 'R');
+		pr_err("%s: bad direction, %c (req->write && (descq->conf.q_type != Q_H2C) = %d (!req->write && (descq->conf.q_type != Q_C2H)) = %d descq->conf.q_type = %s.\n",
+			descq->conf.name, req->write ? 'W' : 'R', (req->write && (descq->conf.q_type != Q_H2C)), (!req->write && (descq->conf.q_type != Q_C2H)), (descq->conf.q_type == Q_C2H) ? "C2H" : "H2C");
 		return -EINVAL;
 	}
 
diff --git a/libqdma/libqdma_export.h b/libqdma/libqdma_export.h
index 75d4cdf..ec0d6e6 100644
--- a/libqdma/libqdma_export.h
+++ b/libqdma/libqdma_export.h
@@ -37,6 +37,7 @@
 
 #include <linux/types.h>
 #include <linux/interrupt.h>
+#include <linux/dma-mapping.h>
 #include "libqdma_config.h"
 #include "qdma_access_export.h"
 
@@ -805,6 +806,9 @@ struct qdma_request {
 	struct qdma_sw_sg *sgl;
 	/**  udd data */
 	u8 udd[QDMA_UDD_MAXLEN];
+
+	/* Device available offset position */
+    u64 offset_pos;
 };
 
 /**
diff --git a/libqdma/qdma_descq.c b/libqdma/qdma_descq.c
index 7470097..41dbaf6 100644
--- a/libqdma/qdma_descq.c
+++ b/libqdma/qdma_descq.c
@@ -1459,8 +1459,9 @@ int qdma_descq_service_cmpl_update(struct qdma_descq *descq, int budget,
 
 ssize_t qdma_descq_proc_sgt_request(struct qdma_descq *descq)
 {
-	if (!descq->conf.st) /* MM H2C/C2H */
+	if (!descq->conf.st) /* MM H2C/C2H */{
 		return descq_mm_proc_request(descq);
+	}
 	else if (descq->conf.st && (descq->conf.q_type == Q_H2C)) {/* ST H2C */
 		if (descq->conf.fp_bypass_desc_fill &&
 			descq->conf.desc_bypass &&
@@ -1496,7 +1497,6 @@ void qdma_sgt_req_done(struct qdma_descq *descq, struct qdma_sgt_req_cb *cb,
 			int error)
 {
 	struct qdma_request *req = (struct qdma_request *)cb;
-
 	if (unlikely(error))
 		pr_err("req 0x%p, cb 0x%p, fp_done 0x%p done, err %d.\n",
 			req, cb, req->fp_done, error);
diff --git a/libqdma/qdma_device.h b/libqdma/qdma_device.h
index 375a12c..943b5af 100644
--- a/libqdma/qdma_device.h
+++ b/libqdma/qdma_device.h
@@ -58,6 +58,12 @@ struct qdma_dev {
 	struct qdma_descq *c2h_descq;
 	/** cmpt descq list */
 	struct qdma_descq *cmpt_descq;
+
+    struct pci_dev *pdev;
+    u16 func_id;
+    u16 q_base;
+    u16 num_queues;
+    void __iomem *addr; /* mapped address of device registers */
 };
 
 /**
diff --git a/libqdma/qdma_st_c2h.c b/libqdma/qdma_st_c2h.c
index db793cd..42f68d8 100644
--- a/libqdma/qdma_st_c2h.c
+++ b/libqdma/qdma_st_c2h.c
@@ -215,8 +215,13 @@ static inline int flq_fill_page_one(struct qdma_sw_pg_sg *pg_sdesc,
 		return -ENOMEM;
 	}
 
+#if LINUX_VERSION_CODE < KERNEL_VERSION(5, 18, 0)
 	mapping = dma_map_page(dev, pg, 0, (PAGE_SIZE << pg_order),
 				PCI_DMA_FROMDEVICE);
+#else // LINUX_VERSION_CODE >= KERNEL_VERSION(5, 18, 0)
+	mapping = dma_map_page(dev, pg, 0, (PAGE_SIZE << pg_order),
+				DMA_FROM_DEVICE);
+#endif
 	if (unlikely(dma_mapping_error(dev, mapping))) {
 		dev_err(dev, "page 0x%p mapping error 0x%llx.\n",
 			pg, (unsigned long long)mapping);
diff --git a/libqdma/xdev.c b/libqdma/xdev.c
index 770c395..7474ffa 100644
--- a/libqdma/xdev.c
+++ b/libqdma/xdev.c
@@ -91,6 +91,7 @@ struct qdma_resource_lock {
 static int pci_dma_mask_set(struct pci_dev *pdev)
 {
 	/** 64-bit addressing capability for XDMA? */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(5, 18, 0)
 	if (!pci_set_dma_mask(pdev, DMA_BIT_MASK(64))) {
 		/** use 64-bit DMA for descriptors */
 		pci_set_consistent_dma_mask(pdev, DMA_BIT_MASK(64));
@@ -104,6 +105,21 @@ static int pci_dma_mask_set(struct pci_dev *pdev)
 		dev_info(&pdev->dev, "No suitable DMA possible.\n");
 		return -EINVAL;
 	}
+#else // LINUX_VERSION_CODE >= KERNEL_VERSION(5, 18, 0)
+	if (!dma_set_mask(&pdev->dev, (u64) DMA_BIT_MASK(64))) {
+		/** use 64-bit DMA for descriptors */
+		dma_set_coherent_mask(&pdev->dev, (u64) DMA_BIT_MASK(64));
+		/** use 64-bit DMA, 32-bit for consistent */
+	} else if (!dma_set_mask(&pdev->dev, (u64) DMA_BIT_MASK(32))) {
+		dma_set_coherent_mask(&pdev->dev, (u64) DMA_BIT_MASK(32));
+		/** use 32-bit DMA */
+		dev_info(&pdev->dev, "Using a 32-bit DMA mask.\n");
+	} else {
+		/** use 32-bit DMA */
+		dev_info(&pdev->dev, "No suitable DMA possible.\n");
+		return -EINVAL;
+	}
+#endif
 
 	return 0;
 }
diff --git a/onic.h b/onic.h
index e2b8865..4bbcbdc 100644
--- a/onic.h
+++ b/onic.h
@@ -3,7 +3,6 @@
 
 #include <linux/netdevice.h>
 #include <linux/cpumask.h>
-#include "onic_json.h"
 #include "libqdma_export.h"
 #include "onic_register.h"
 #include "qdma_access/qdma_access_common.h"
@@ -15,39 +14,88 @@
 #define ONIC_RX_PULL_LEN                    (128)
 #define ONIC_NAPI_WEIGHT                    (64)
 
+#define DRV_CDEV_NAME "reconic-mm"
+#include "onic_cdev.h"
+
+#define QDMA_BAR 0
+#define QDMA_USER_BAR 2
+#define QDMA_QUEUE_BASE 0
+#define QDMA_QUEUE_MAX 1024
+#define CMAC_PORT_ID 0
+#define QDMA_MM_QUEUE 4
+#define QDMA_NET_QUEUE 64
+#define QMDA_TOTAL_QUEUE_ACTIVE (QDMA_MM_QUEUE + QDMA_NET_QUEUE)
+#define RING_SIZE 1024
+#define C2H_TMR_CNT 5
+#define C2H_CNT_THR 64
+#define C2H_BUF_SIZE 1024
+#define PCI_MSIX_USER_CNT 1
+
+#define CMAC_RX_LANE_ALIGNMENT_RESET_CNT 8
+#define CMAC_RX_LANE_ALIGNMENT_TIMEOUT_CNT 32
+
+struct qdma_fmap_ctxt {
+    u32 qbase:11;
+    u32 rsvd0:21;
+    u32 qmax:12;
+    u32 rsvd1:20;
+};
 
 struct onic_dma_request {
-	struct sk_buff *skb;
-	struct net_device *netdev;
-	struct qdma_request qdma;
-	struct qdma_sw_sg sgl[MAX_SKB_FRAGS];
+  struct sk_buff *skb;
+  struct net_device *netdev;
+  struct qdma_request qdma;
+  struct qdma_sw_sg sgl[MAX_SKB_FRAGS];
+};
+
+struct onic_platform_info {
+  u8 qdma_bar;
+  u8 user_bar;
+  u16 queue_base;
+  u16 queue_max;
+  u16 used_queues;
+  u16 active_tx_queues;
+  u16 active_rx_queues;
+  u16 mm_queues;
+  u8 pci_msix_user_cnt;
+  bool pci_master_pf;
+  bool poll_mode;
+  bool intr_mod_en;
+  int ring_sz;
+  int c2h_tmr_cnt;
+  int c2h_cnt_thr;
+  int c2h_buf_sz;
+  bool rsfec_en;
+  u8 port_id;
+  u8 mac_addr[6];
 };
 
 /* ONIC Net device private structure */
 struct onic_priv {
-	u8 rx_desc_rng_sz_idx;
-	u8 tx_desc_rng_sz_idx;
-	u8 rx_buf_sz_idx;
-	u8 rx_timer_idx;
-	u8 rx_cnt_th_idx;
-	u8 cmpl_rng_sz_idx;
-
-	struct net_device *netdev;
-	struct pci_dev *pcidev;
-	struct onic_platform_info *pinfo;
+  u8 rx_desc_rng_sz_idx;
+  u8 tx_desc_rng_sz_idx;
+  u8 rx_buf_sz_idx;
+  u8 rx_timer_idx;
+  u8 rx_cnt_th_idx;
+  u8 cmpl_rng_sz_idx;
 
-	u16 num_msix;
-	u16 nb_queues;
+  struct net_device *netdev;
+  struct pci_dev *pcidev;
+  struct onic_platform_info *pinfo;
 
-	struct kmem_cache *dma_req;
-	struct qdma_dev_conf qdma_dev_conf;
-	unsigned long dev_handle;
-	void __iomem *bar_base;
+  u16 num_msix;
+  u16 nb_queues;
 
-	unsigned long base_tx_q_handle, base_rx_q_handle;
-	struct napi_struct *napi;
-	struct rtnl_link_stats64 *tx_qstats, *rx_qstats;
+  struct kmem_cache *dma_req;
+  struct qdma_dev_conf qdma_dev_conf;
+  struct qdma_dev* qdev;
+  unsigned long dev_handle;
+  void __iomem *bar_base;
 
+  unsigned long base_tx_q_handle, base_rx_q_handle;
+  struct napi_struct *napi;
+  struct rtnl_link_stats64 *tx_qstats, *rx_qstats;
+  struct onic_cdev *onic_cdev_ptr;
 };
 
 #endif /* ONIC_H */
diff --git a/onic_cdev.c b/onic_cdev.c
new file mode 100755
index 0000000..228eedb
--- /dev/null
+++ b/onic_cdev.c
@@ -0,0 +1,474 @@
+/*
+ * Copyright (c) 2021 Xilinx, Inc.
+ * All rights reserved.
+ *
+ * This source code is free software; you can redistribute it and/or modify it
+ * under the terms and conditions of the GNU General Public License,
+ * version 2, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ *
+ * The full GNU General Public License is included in this distribution in
+ * the file called "COPYING".
+ */
+#include "onic_cdev.h"
+#include <linux/pci.h>
+#include <linux/syscalls.h>
+/**
+ * sysfs class structure
+ **/
+static struct class *onic_cdev_class = NULL;
+
+// synchronisation
+// for read synchronisation
+static struct semaphore read_sem;
+static struct semaphore read_mutex;
+static struct semaphore read_mutex2;
+static int read_read_idx;
+static int read_write_idx;
+static int *read_queue_pool;
+// for write synchronisation
+static struct semaphore write_sem;
+static struct semaphore write_mutex;
+static struct semaphore write_mutex2;
+static int write_read_idx;
+static int write_write_idx;
+static int *write_queue_pool;
+
+/**
+ * Minor of this char device
+ **/
+static int cdev_minor = 0;
+
+/**
+ * Open a character device and initialize private data
+ **/
+static int onic_cdev_open(struct inode *inode, struct file *file) {
+  struct onic_cdev *onic_cdev_ptr = container_of(inode->i_cdev, struct onic_cdev, mm_cdev);
+  file->private_data = onic_cdev_ptr;
+  dev_dbg(&onic_cdev_ptr->qdev->pdev->dev, "%s: Open onic_cdev.\n", onic_cdev_ptr->name);
+  return 0;
+}
+
+/**
+ * Close a character device
+ **/
+static int onic_cdev_close(struct inode *inode, struct file *file) {
+  // Do nothing
+  struct onic_cdev *onic_cdev_ptr = (struct onic_cdev*) file->private_data;
+  dev_info(&onic_cdev_ptr->qdev->pdev->dev, "%s: Close onic_cdev.\n", onic_cdev_ptr->name);
+  return 0;
+}
+
+static long onic_cdev_ioctl(
+  struct file *file,	/* ditto */
+  unsigned int ioctl_num,	/* number and param for ioctl */
+  unsigned long ioctl_param){
+	return 0;
+}
+
+static void unmap_user_buf(struct cdev_io_cb *iocb, bool write)
+{
+  int i;
+
+  if (!iocb->pages || !iocb->page_nb)
+    return;
+
+  for (i = 0; i < iocb->page_nb; i++) {
+    if (iocb->pages[i]) {
+      if (!write)
+        set_page_dirty(iocb->pages[i]);
+      put_page(iocb->pages[i]);
+    } else{
+      break;
+    }
+  }
+
+  if (i != iocb->page_nb)
+    pr_err("sgl pages %d/%u.\n", i, iocb->page_nb);
+
+  iocb->page_nb = 0;
+}
+
+/*
+ * cdev r/w
+ */
+static inline void iocb_release(struct cdev_io_cb *iocb)
+{
+  if (iocb->pages)
+    iocb->pages = NULL;
+  kfree(iocb->sgl);
+  iocb->sgl = NULL;
+  iocb->buf = NULL;
+}
+
+static int map_user_buf_to_sgl(struct cdev_io_cb *iocb, bool write)
+{
+  unsigned long len = iocb->len;
+  char *buf = iocb->buf;
+  struct qdma_sw_sg *sg;
+  unsigned int pg_off = offset_in_page(buf);
+  unsigned int pages_nr = (len + pg_off + PAGE_SIZE - 1) >> PAGE_SHIFT;
+  int i;
+  int rv;
+
+  if (len == 0)
+    pages_nr = 1;
+  if (pages_nr == 0)
+    return -EINVAL;
+
+  iocb->page_nb = 0;
+  sg = kmalloc(pages_nr * (sizeof(struct qdma_sw_sg) +
+          sizeof(struct page *)), GFP_KERNEL);
+  if (!sg) {
+    pr_err("sgl allocation failed for %u pages", pages_nr);
+    return -ENOMEM;
+  }
+
+  memset(sg, 0, pages_nr * (sizeof(struct qdma_sw_sg) +
+          sizeof(struct page *)));
+  iocb->sgl = sg;
+
+  iocb->pages = (struct page **)(sg + pages_nr);
+  rv = get_user_pages_fast((unsigned long)buf, pages_nr, 1/* write */,
+              iocb->pages);
+  /* No pages were pinned */
+  if (rv < 0) {
+    pr_err("unable to pin down %u user pages, %d.\n",
+        pages_nr, rv);
+    goto err_out;
+  }
+  /* Less pages pinned than wanted */
+  if (rv != pages_nr) {
+    pr_err("unable to pin down all %u user pages, %d.\n",
+        pages_nr, rv);
+    iocb->page_nb = rv;
+    rv = -EFAULT;
+    goto err_out;
+  }
+
+  for (i = 1; i < pages_nr; i++) {
+    if (iocb->pages[i - 1] == iocb->pages[i]) {
+      pr_err("duplicate pages, %d, %d.\n",
+          i - 1, i);
+      iocb->page_nb = pages_nr;
+      rv = -EFAULT;
+      goto err_out;
+    }
+  }
+
+  sg = iocb->sgl;
+  for (i = 0; i < pages_nr; i++, sg++) {
+    unsigned int offset = offset_in_page(buf);
+    unsigned int nbytes = min_t(unsigned int, PAGE_SIZE - offset,
+                    len);
+    struct page *pg = iocb->pages[i];
+
+    flush_dcache_page(pg);
+
+    sg->next = sg + 1;
+    sg->pg = pg;
+    sg->offset = offset;
+    sg->len = nbytes;
+    sg->dma_addr = 0UL;
+
+    buf += nbytes;
+    len -= nbytes;
+  }
+
+  iocb->sgl[pages_nr - 1].next = NULL;
+  iocb->page_nb = pages_nr;
+
+  return 0;
+
+err_out:
+  unmap_user_buf(iocb, write);
+  iocb_release(iocb);
+
+  return rv;
+}
+
+static ssize_t onic_gen_read_write(struct file *file, char __user *buf,
+        size_t count, loff_t *pos, bool write, int target_queue)
+{
+  struct onic_cdev *xcdev = (struct onic_cdev *)file->private_data;
+  struct cdev_io_cb iocb;
+  struct qdma_request *req = &iocb.qd_req;
+  ssize_t res = 0;
+  int rv;
+  unsigned long qhndl;
+
+  if (!xcdev) {
+    pr_err("file 0x%p, xcdev NULL, 0x%p,%llu, pos %llu, W %d.\n",
+        file, buf, (u64)count, (u64)*pos, write);
+    return -EINVAL;
+  }
+
+  if (!xcdev->fp_rw) {
+    pr_err("file 0x%p, %s, NO rw, 0x%p,%llu, pos %llu, W %d.\n",
+        file, xcdev->name, buf, (u64)count, (u64)*pos, write);
+    return -EINVAL;
+  }
+
+  qhndl = write ? xcdev->mm_h2c_q_hndl + target_queue : xcdev->mm_c2h_q_hndl + target_queue;
+
+  pr_debug("%s, priv 0x%lx: buf 0x%p,%llu, pos %llu, W %d.\n",
+      xcdev->name, qhndl, buf, (u64)count, (u64)*pos,
+      write);
+
+  memset(&iocb, 0, sizeof(struct cdev_io_cb));
+  iocb.buf = buf;
+  iocb.len = count;
+  rv = map_user_buf_to_sgl(&iocb, write);
+  if (rv < 0)
+    return rv;
+
+  req->sgcnt = iocb.page_nb;
+  req->sgl = iocb.sgl;
+  req->write = write ? 1 : 0;
+  req->dma_mapped = 0;
+  req->udd_len = 0;
+  req->ep_addr = (u64)*pos;
+  req->count = count;
+  req->timeout_ms = 10 * 1000;    /* 10 seconds */
+  req->fp_done = NULL;        /* blocking */
+  req->h2c_eot = 1;        /* set to 1 for STM tests */
+
+  res = xcdev->fp_rw(xcdev->dev_handle, qhndl, req);
+
+  unmap_user_buf(&iocb, write);
+  iocb_release(&iocb);
+
+  if(!write){
+    down(&read_mutex2);
+    read_queue_pool[read_write_idx] = target_queue;
+    read_write_idx = (read_write_idx + 1) % xcdev->no_mm_queues;
+    up(&read_mutex2);
+    up(&read_sem);
+  }
+  else{
+    down(&write_mutex2);
+    write_queue_pool[write_write_idx] = target_queue;
+    write_write_idx = (write_write_idx + 1) % xcdev->no_mm_queues;
+    up(&write_mutex2);
+    up(&write_sem);
+  }
+
+  return res;
+}
+
+/**
+ * Write operation for a character device
+ **/
+static ssize_t onic_cdev_write(struct file *file, const char __user *usr_buf, size_t count, loff_t *offset) {
+  struct onic_cdev *onic_cdev_ptr = (struct onic_cdev*) file->private_data;
+  int target_queue;
+  down(&write_sem);
+  down(&write_mutex);
+  target_queue = write_queue_pool[write_read_idx];
+  write_read_idx = (write_read_idx + 1) % onic_cdev_ptr->no_mm_queues;
+  up(&write_mutex);
+  dev_dbg(&onic_cdev_ptr->qdev->pdev->dev, "Write obtained queue %d\n", target_queue);
+  return onic_gen_read_write(file, (char *) usr_buf, count, offset, 1, target_queue);
+}
+
+/**
+ * Read operation for a character device
+ **/
+static ssize_t onic_cdev_read(struct file *file, char __user *usr_buf, size_t count, loff_t *offset) {
+  struct onic_cdev *onic_cdev_ptr = (struct onic_cdev*) file->private_data;
+  int target_queue;
+  down(&read_sem);
+  down(&read_mutex);
+  target_queue = read_queue_pool[read_read_idx];
+  read_read_idx = (read_read_idx + 1) % onic_cdev_ptr->no_mm_queues;
+  up(&read_mutex);
+  dev_dbg(&onic_cdev_ptr->qdev->pdev->dev, "Read obtained queue %d\n", target_queue);
+  return onic_gen_read_write(file, (char *) usr_buf, count, offset, 0, target_queue);
+}
+
+/**
+ * Set offset in the character device
+ */
+static loff_t onic_cdev_llseek(struct file *file, loff_t off, int whence) {
+  struct onic_cdev *onic_cdev_ptr = (struct onic_cdev*) file->private_data;
+
+  loff_t newpos = 0;
+
+  switch (whence) {
+  case 0: /* SEEK_SET */
+    newpos = off;
+    break;
+  case 1: /* SEEK_CUR */
+    newpos = file->f_pos + off;
+    break;
+  case 2: /* SEEK_END, @TODO should work from end of address space */
+    newpos = UINT_MAX + off;
+    break;
+  default: /* can't happen */
+    return -EINVAL;
+  }
+  if (newpos < 0)
+    return -EINVAL;
+  file->f_pos = newpos;
+
+  dev_dbg(&onic_cdev_ptr->qdev->pdev->dev, "%s: pos=%lld\n", onic_cdev_ptr->name, (signed long long)newpos);
+
+  return newpos;
+}
+
+/**
+ * File operation registration
+ **/
+static const struct file_operations onic_cdev_fops = {
+  .read         = onic_cdev_read,
+  .write        = onic_cdev_write,
+  .unlocked_ioctl = onic_cdev_ioctl,
+  .open         = onic_cdev_open,
+  .release      = onic_cdev_close,
+  .llseek       = onic_cdev_llseek,
+};
+
+int onic_init_cdev(struct onic_cdev *onic_cdev_ptr, int no_mm_queues) {
+  int i;
+
+  sema_init(&read_sem, no_mm_queues);
+  sema_init(&read_mutex, 1);
+  sema_init(&read_mutex2, 1);
+  read_read_idx = 0;
+  read_write_idx = 0;
+
+  for(i = 0 ; i < no_mm_queues ; i++){
+    read_queue_pool[i] = i;
+  }
+
+  sema_init(&write_sem, no_mm_queues);
+  sema_init(&write_mutex, 1);
+  sema_init(&write_mutex2, 1);
+  write_read_idx = 0;
+  write_write_idx = 0;
+  for(i = 0 ; i < no_mm_queues ; i++){
+    write_queue_pool[i] = i;
+  }
+  return 0;
+}
+
+int onic_create_cdev(struct onic_cdev *onic_cdev_ptr, struct onic_priv * xpriv, unsigned int qid) {
+  int err;
+  struct device* sysfs_dev;
+  struct xlnx_dma_dev *xdev;
+  dev_t dev;
+  int no_mm_queues;
+
+  onic_cdev_ptr->cdev_minor_cnt = MAX_MINOR_DEV;
+
+  xdev = (struct xlnx_dma_dev *)xpriv->dev_handle;
+  no_mm_queues = xpriv->pinfo->mm_queues;
+
+  onic_cdev_ptr->dev_handle = xpriv->dev_handle;
+  xpriv->onic_cdev_ptr = onic_cdev_ptr;
+  xpriv->onic_cdev_ptr->qdev = xdev_2_qdev(xdev);
+  xpriv->onic_cdev_ptr->xpriv = xpriv;
+  xpriv->onic_cdev_ptr->qdev->pdev = xpriv->pcidev;
+
+  onic_cdev_ptr->fp_rw = qdma_request_submit;
+  onic_cdev_ptr->no_mm_queues = no_mm_queues;
+
+  read_queue_pool = (int*) kzalloc(sizeof(int) * no_mm_queues, GFP_KERNEL);
+  write_queue_pool = (int*) kzalloc(sizeof(int) * no_mm_queues, GFP_KERNEL);
+
+  // Create a cdev class
+  onic_cdev_class = class_create(THIS_MODULE, ONIC_CDEV_CLASS_NAME);
+
+  if(IS_ERR(onic_cdev_class)) {
+    dev_err(&onic_cdev_ptr->qdev->pdev->dev, "%s: failed to create open-nic cdev class.",
+            ONIC_CDEV_CLASS_NAME);
+    onic_cdev_class = NULL;
+    // return error with no such device
+    return -ENODEV;
+  }
+
+  // allocate a range of character device number. The major number will be chosen dynamically
+  err = alloc_chrdev_region(&dev, 0, onic_cdev_ptr->cdev_minor_cnt, ONIC_CDEV_CLASS_NAME);
+  if(err) {
+    dev_err(&onic_cdev_ptr->qdev->pdev->dev, "unable to allocate character device region %d.\n", err);
+    return err;
+  }
+
+  onic_cdev_ptr->cdev_major = MAJOR(dev);
+  sprintf(onic_cdev_ptr->name, "%s", ONIC_CDEV_CLASS_NAME);
+  //dev_info(&onic_cdev_ptr->qdev->pdev->dev, "onic_cdev_ptr->name = %s\n", onic_cdev_ptr->name);
+
+  onic_cdev_ptr->mm_cdev.owner = THIS_MODULE;
+  if(qid >= onic_cdev_ptr->cdev_minor_cnt) {
+    dev_err(&onic_cdev_ptr->qdev->pdev->dev, "%s: No character device available!\n", onic_cdev_ptr->name);
+    onic_cdev_ptr->cdev_minor = cdev_minor;
+    return -1;
+  }else{
+    cdev_minor = qid;
+    onic_cdev_ptr->cdev_minor    = cdev_minor;
+  }
+  onic_cdev_ptr->cdev_no = MKDEV(onic_cdev_ptr->cdev_major, onic_cdev_ptr->cdev_minor);
+
+  // Initialize the char device with its file operations
+  cdev_init(&(onic_cdev_ptr->mm_cdev), &onic_cdev_fops);
+
+  // Add the device to the system
+  err = cdev_add(&onic_cdev_ptr->mm_cdev, onic_cdev_ptr->cdev_no, 1);
+  if(err < 0){
+    dev_err(&onic_cdev_ptr->qdev->pdev->dev, "cdev_add failed %d, %s\n", err, onic_cdev_ptr->name);
+    return err;
+  } else {
+    dev_info(&onic_cdev_ptr->qdev->pdev->dev, "successfully cdev_add a character device, %s, to the system", onic_cdev_ptr->name);
+  }
+
+  // Create a device file node and register it with sysfs
+  if(onic_cdev_class){
+    sysfs_dev = device_create(onic_cdev_class, &(onic_cdev_ptr->qdev->pdev->dev), onic_cdev_ptr->cdev_no, NULL, "%s", onic_cdev_ptr->name);
+    if(IS_ERR(sysfs_dev)) {
+      err = PTR_ERR(sysfs_dev);
+      dev_err(&onic_cdev_ptr->qdev->pdev->dev, "%s: device_create failed %d\n", onic_cdev_ptr->name, err);
+      cdev_del(&onic_cdev_ptr->mm_cdev);
+      return err;
+    } else {
+      dev_info(&onic_cdev_ptr->qdev->pdev->dev, "successffully device_create a character device, %s, and register it", onic_cdev_ptr->name);
+    }
+  }
+
+  return 0;
+}
+
+void onic_destroy_cdev(struct onic_cdev *onic_cdev_ptr) {
+  dev_info(&onic_cdev_ptr->qdev->pdev->dev, "%s cdev_major=%d before destroyed\n", onic_cdev_ptr->name, onic_cdev_ptr->cdev_major);
+  cdev_del(&onic_cdev_ptr->mm_cdev);
+
+  if(cdev_minor>=0) {
+    device_destroy(onic_cdev_class, onic_cdev_ptr->cdev_no);
+    dev_info(&onic_cdev_ptr->qdev->pdev->dev, "%s device_destroy done!\n", onic_cdev_ptr->name);
+  } else {
+    dev_err(&onic_cdev_ptr->qdev->pdev->dev, "%s device_destroy failed!\n", onic_cdev_ptr->name);
+  }
+
+  // Remove sysfs class for this char device
+  if(onic_cdev_class) {
+    //class_unregister(onic_cdev_class);
+    class_destroy(onic_cdev_class);
+    unregister_chrdev_region(MKDEV(onic_cdev_ptr->cdev_major, 0), MAX_MINOR_DEV);
+    dev_info(&onic_cdev_ptr->qdev->pdev->dev, "%s class_unregister, class_destroy and unregister_chrdev_region done!\n", onic_cdev_ptr->name);
+  } else {
+    dev_err(&onic_cdev_ptr->qdev->pdev->dev, "%s class_unregister, class_destroy and unregister_chrdev_region failed!\n", onic_cdev_ptr->name);
+  }
+
+  // Reset major number assigned to this char device
+  if(onic_cdev_ptr->cdev_major) {
+    onic_cdev_ptr->cdev_major = 0;
+      dev_info(&onic_cdev_ptr->qdev->pdev->dev, "%s cdev_major is reset to %d, onic_destroy_cdev done\n", onic_cdev_ptr->name, onic_cdev_ptr->cdev_major);
+  }
+
+  kfree(read_queue_pool);
+  kfree(write_queue_pool);
+  kfree(onic_cdev_ptr);
+}
diff --git a/onic_cdev.h b/onic_cdev.h
new file mode 100755
index 0000000..85fc0bd
--- /dev/null
+++ b/onic_cdev.h
@@ -0,0 +1,125 @@
+/*
+ * Copyright (c) 2021 Xilinx, Inc.
+ * All rights reserved.
+ *
+ * This source code is free software; you can redistribute it and/or modify it
+ * under the terms and conditions of the GNU General Public License,
+ * version 2, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ *
+ * The full GNU General Public License is included in this distribution in
+ * the file called "COPYING".
+ */
+#ifndef __ONIC_CDEV_H__
+#define __ONIC_CDEV_H__
+
+#include <linux/cdev.h>
+#include "onic.h"
+//#include "qdma_access/qdma_export.h"
+#include "libqdma/libqdma_export.h"
+#include "libqdma/qdma_device.h"
+#include <asm/cacheflush.h>
+#include <linux/syscalls.h>
+#include <linux/semaphore.h>
+
+#define ONIC_CDEV_CLASS_NAME DRV_CDEV_NAME
+#define MAX_MINOR_DEV 64
+
+/**
+ * Data structure for a character device
+ **/
+struct onic_cdev {
+  /* pointer to PCIe device handler */
+  struct qdma_dev* qdev;
+  /* Generic character device interface */
+  struct cdev mm_cdev;
+  /* Minor number */
+  int cdev_minor;
+  /* Major number */
+  int cdev_major;
+  /* Character device number */
+  dev_t cdev_no;
+  /* Minor number count */
+  int cdev_minor_cnt;
+  /* c2h queue handle */
+  unsigned long mm_c2h_q_hndl;
+  /* h2c queue handle */
+  unsigned long mm_h2c_q_hndl;
+  int no_mm_queues;
+  unsigned long dev_handle;
+  /* callback function to handle read/write request */
+  ssize_t (*fp_rw)(unsigned long xpdev_hndl, unsigned long q_hndl, struct qdma_request *qd_req);
+  /* name of the character device */
+  char name[0];
+  struct onic_priv *xpriv;
+  //struct net_device *netdev;
+
+  int read_idx;
+  int write_idx;
+
+};
+
+/**
+ * Data structure for io callback of a character device
+ **/
+struct cdev_io_cb {
+  void *private;
+  /* pointer to the user buffer */
+  void __user *buf;
+  /* length of the user buffer */
+  size_t len;
+  /* page number */
+  unsigned int page_nb;
+  /* scatter gather list */
+  struct qdma_sw_sg *sgl;
+  /* pages allocated to accommodate the scatter gather list */
+  struct page **pages;
+  /* qdma request */
+  struct qdma_request qd_req;
+};
+
+/**
+ * qdma scatter gather request
+ * @ingroup libqdma_struct
+ *
+ */
+//struct qdma_sw_sg {
+    /** pointer to next page */
+//    struct qdma_sw_sg *next;
+    /** pointer to current page */
+//    struct page *pg;
+    /** offset in current page */
+//    unsigned int offset;
+    /** length of the page */
+//    unsigned int len;
+    /** dma address of the allocated page */
+//    dma_addr_t dma_addr;
+//};
+
+/**
+ * onic_init_cdev - initilize a character device
+ * @onic_cdev_ptr: pointer to an onic_cdev data
+ * Return 0 on success, negative on failure
+ **/
+int onic_init_cdev(struct onic_cdev *onic_cdev_ptr, int no_mm_queues);
+
+/**
+ * onic_destroy_cdev - destroy a character device
+ * @onic_cdev_ptr: pointer to an onic_cdev data
+ **/
+void onic_destroy_cdev(struct onic_cdev *onic_cdev_ptr);
+
+/**
+ * onic_create_cdev - create a character device
+ * @onic_cdev_ptr: pointer to an onic_cdev data
+ * @xpriv: ONIC private data
+ * @qid: QDMA qid as a char device minor number
+ * Return 0 on success, negative on failure
+ **/
+int onic_create_cdev(struct onic_cdev *onic_cdev_ptr, struct onic_priv * xpriv, unsigned int qid);
+
+#endif /* ifndef __ONIC_CDEV_H__ */
diff --git a/onic_json.c b/onic_json.c
deleted file mode 100644
index 0e0f7f0..0000000
--- a/onic_json.c
+++ /dev/null
@@ -1,196 +0,0 @@
-#include <linux/kernel.h>
-#include <linux/slab.h>
-#include <linux/firmware.h>
-#include "onic_json.h"
-#include "jsmn.h"
-
-static bool jsoneq(const char *json, jsmntok_t *tok, const char *s)
-{
-	if (tok->type == JSMN_STRING && (int)strlen(s) == tok->end - tok->start
-	    && strncmp(json + tok->start, s, tok->end - tok->start) == 0)
-		return true;
-	else
-		return false;
-}
-
-#define PARSEBUF_LEN 32
-int onic_get_platform_info(char *fname, struct onic_platform_info *pinfo)
-{
-	int err = 0;
-	char fw_name[256];
-	const struct firmware *fw;
-	const char *jsonBuffer;
-	u16 length;
-	jsmn_parser parser;
-	jsmntok_t *tokens;
-	u16 numTokens;
-	char parsingBuffer[PARSEBUF_LEN];
-	int i,j;
-
-	snprintf(fw_name, sizeof(fw_name), "xilinx/%s", fname);
-
-	err = request_firmware(&fw, fw_name, NULL);
-	if (err) {
-		pr_err("%s: request_firmware failed : %d\n", __func__, err);
-		return err;
-	}
-	jsonBuffer = fw->data;
-	length = fw->size;
-
-	/* initialize the JSMN parser and determine the number of JSON tokens */
-	jsmn_init(&parser);
-	numTokens = jsmn_parse(&parser, jsonBuffer, length, NULL, 0);
-
-	/* The JSON file must be tokenized successfully. */
-	if (numTokens < 1) {
-		pr_err("%s: 1st jsmn_parse failed : %d\n", __func__, numTokens);
-		err = -EINVAL;
-		goto func_exit;
-	}
-
-	/* allocate space for tokens */
-	tokens = (jsmntok_t *)kcalloc(numTokens, sizeof(jsmntok_t), GFP_KERNEL);
-	if (tokens == NULL) {
-		pr_err("%s: tokens array allocation failed.\n", __func__);
-		err = -ENOMEM;
-		goto func_exit;
-	}
-
-	/* initialize the JSMN paser and parse the json file into the tokens
-	 * array */
-	jsmn_init(&parser);
-	numTokens = jsmn_parse(&parser, jsonBuffer, length, tokens, numTokens);
-
-	/* The top-level element must be an object. */
-	if (numTokens < 1 || tokens[0].type != JSMN_OBJECT) {
-		kfree(tokens);
-		pr_err("%s: 2nd jsmn_parse failed : %d\n", __func__, numTokens);
-		err = -EINVAL;
-		goto func_exit;
-	}
-
-	/* Loop over all keys of the root object */
-	for (i = 1; i < numTokens; i++) {
-		if (jsoneq(jsonBuffer, &tokens[i], "qdma_bar")) {
-			snprintf(parsingBuffer, PARSEBUF_LEN, "%.*s",
-				 tokens[i+1].end - tokens[i+1].start, jsonBuffer
-				 + tokens[i+1].start);
-			kstrtou8(parsingBuffer, 10, &pinfo->qdma_bar);
-			i++;
-		} else if (jsoneq(jsonBuffer, &tokens[i], "user_bar")) {
-			snprintf(parsingBuffer, PARSEBUF_LEN, "%.*s",
-				 tokens[i+1].end - tokens[i+1].start, jsonBuffer
-				 + tokens[i+1].start);
-			kstrtou8(parsingBuffer, 10, &pinfo->user_bar);
-			i++;
-		} else if (jsoneq(jsonBuffer, &tokens[i], "queue_base")) {
-			snprintf(parsingBuffer, PARSEBUF_LEN, "%.*s",
-				 tokens[i+1].end - tokens[i+1].start, jsonBuffer
-				 + tokens[i+1].start);
-			kstrtou16(parsingBuffer, 10, &pinfo->queue_base);
-			i++;
-		} else if (jsoneq(jsonBuffer, &tokens[i], "queue_max")) {
-			snprintf(parsingBuffer, PARSEBUF_LEN, "%.*s",
-				 tokens[i+1].end - tokens[i+1].start, jsonBuffer
-				 + tokens[i+1].start);
-			kstrtou16(parsingBuffer, 10, &pinfo->queue_max);
-			i++;
-		} else if (jsoneq(jsonBuffer, &tokens[i], "used_queues")) {
-			snprintf(parsingBuffer, PARSEBUF_LEN, "%.*s",
-				 tokens[i+1].end - tokens[i+1].start, jsonBuffer
-				 + tokens[i+1].start);
-			kstrtou16(parsingBuffer, 10, &pinfo->used_queues);
-			i++;
-		} else if (jsoneq(jsonBuffer, &tokens[i], "pci_msix_user_cnt")) {
-			snprintf(parsingBuffer, PARSEBUF_LEN, "%.*s",
-				 tokens[i+1].end - tokens[i+1].start, jsonBuffer
-				 + tokens[i+1].start);
-			kstrtou8(parsingBuffer, 10, &pinfo->pci_msix_user_cnt);
-			i++;
-		} else if (jsoneq(jsonBuffer, &tokens[i], "pci_master_pf")) {
-			snprintf(parsingBuffer, PARSEBUF_LEN, "%.*s",
-				 tokens[i+1].end - tokens[i+1].start, jsonBuffer
-				 + tokens[i+1].start);
-			pinfo->pci_master_pf = (parsingBuffer[0] != '0') &&
-				(parsingBuffer[0] != 'f') && (parsingBuffer[0]
-							      != 'F');
-			i++;
-		} else if (jsoneq(jsonBuffer, &tokens[i], "poll_mode")) {
-			snprintf(parsingBuffer, PARSEBUF_LEN, "%.*s",
-				 tokens[i+1].end - tokens[i+1].start, jsonBuffer
-				 + tokens[i+1].start);
-			pinfo->poll_mode = (parsingBuffer[0] != '0') &&
-				(parsingBuffer[0] != 'f') && (parsingBuffer[0]
-							      != 'F');
-			i++;
-		} else if (jsoneq(jsonBuffer, &tokens[i], "intr_mod_en")) {
-			snprintf(parsingBuffer, PARSEBUF_LEN, "%.*s",
-				 tokens[i+1].end - tokens[i+1].start, jsonBuffer
-				 + tokens[i+1].start);
-			pinfo->intr_mod_en = (parsingBuffer[0] != '0') &&
-				(parsingBuffer[0] != 'f') && (parsingBuffer[0]
-							      != 'F');
-			i++;
-		} else if (jsoneq(jsonBuffer, &tokens[i], "ring_sz")) {
-			snprintf(parsingBuffer, PARSEBUF_LEN, "%.*s",
-				 tokens[i+1].end - tokens[i+1].start, jsonBuffer
-				 + tokens[i+1].start);
-			kstrtoint(parsingBuffer, 10, &pinfo->ring_sz);
-			i++;
-		} else if (jsoneq(jsonBuffer, &tokens[i], "c2h_tmr_cnt")) {
-			snprintf(parsingBuffer, PARSEBUF_LEN, "%.*s",
-				 tokens[i+1].end - tokens[i+1].start, jsonBuffer
-				 + tokens[i+1].start);
-			kstrtoint(parsingBuffer, 10, &pinfo->c2h_tmr_cnt);
-			i++;
-		} else if (jsoneq(jsonBuffer, &tokens[i], "c2h_cnt_thr")) {
-			snprintf(parsingBuffer, PARSEBUF_LEN, "%.*s",
-				tokens[i+1].end - tokens[i+1].start, jsonBuffer
-				+ tokens[i+1].start);
-			kstrtoint(parsingBuffer, 10, &pinfo->c2h_cnt_thr);
-			i++;
-		} else if (jsoneq(jsonBuffer, &tokens[i], "c2h_buf_sz")) {
-			snprintf(parsingBuffer, PARSEBUF_LEN, "%.*s",
-				 tokens[i+1].end - tokens[i+1].start, jsonBuffer
-				 + tokens[i+1].start);
-			kstrtoint(parsingBuffer, 10, &pinfo->c2h_buf_sz);
-			i++;
-		} else if (jsoneq(jsonBuffer, &tokens[i], "rsfec_en")) {
-			snprintf(parsingBuffer, PARSEBUF_LEN, "%.*s",
-				 tokens[i+1].end - tokens[i+1].start, jsonBuffer
-				 + tokens[i+1].start);
-			pinfo->rsfec_en = (parsingBuffer[0] != '0') &&
-				(parsingBuffer[0] != 'f') && (parsingBuffer[0]
-							      != 'F');
-			i++;
-		} else if (jsoneq(jsonBuffer, &tokens[i], "port_id")) {
-			snprintf(parsingBuffer, PARSEBUF_LEN, "%.*s",
-				 tokens[i+1].end - tokens[i+1].start, jsonBuffer
-				 + tokens[i+1].start);
-			kstrtou8(parsingBuffer, 10, &pinfo->port_id);
-			i++;
-		} else if (jsoneq(jsonBuffer, &tokens[i], "mac_addr")) {
-			if (tokens[i+1].type != JSMN_ARRAY) {
-				continue; /* We expect groups to be an array of
-					     strings */
-			}
-			for (j = 0; j < tokens[i+1].size; j++) {
-				snprintf(parsingBuffer, PARSEBUF_LEN, "%.*s",
-					 tokens[i+j+2].end -
-					 tokens[i+j+2].start, jsonBuffer +
-					 tokens[i+j+2].start);
-				kstrtou8(parsingBuffer, 16,
-					 &pinfo->mac_addr[j]);
-			}
-			i += tokens[i+1].size + 1;
-		} else {
-			pr_err("%s: Unexpected key: %.*s\n", __func__,
-			       tokens[i].end - tokens[i].start,
-			       jsonBuffer + tokens[i].start);
-		}
-	}
-
-func_exit:
-	release_firmware(fw);
-	return err;
-}
diff --git a/onic_json.h b/onic_json.h
deleted file mode 100644
index 84fbdf2..0000000
--- a/onic_json.h
+++ /dev/null
@@ -1,25 +0,0 @@
-#ifndef ONIC_JSON_H
-#define ONIC_JSON_H
-
-struct onic_platform_info {
-	u8 qdma_bar;
-	u8 user_bar;
-	u16 queue_base;
-	u16 queue_max;
-	u16 used_queues;
-	u8 pci_msix_user_cnt;
-	bool pci_master_pf;
-	bool poll_mode;
-	bool intr_mod_en;
-	int ring_sz;
-	int c2h_tmr_cnt;
-	int c2h_cnt_thr;
-	int c2h_buf_sz;
-	bool rsfec_en;
-	u8 port_id;
-	u8 mac_addr[6];
-};
-
-int onic_get_platform_info(char *fname, struct onic_platform_info *pinfo);
-
-#endif
diff --git a/onic_main.c b/onic_main.c
index 1d9107e..7f26c27 100644
--- a/onic_main.c
+++ b/onic_main.c
@@ -14,167 +14,189 @@ char onic_drv_name[] = "onic";
 #define DRV_VER "1.00"
 char onic_drv_ver[] = DRV_VER;
 
+/**
+ * Default MAC address 00:0A:35:00:00:00
+ * First three octets indicate OUI (00:0A:35 for Xilinx)
+ * Note that LSB of the first octet must be 0 (unicast)
+ **/
+static const unsigned char onic_default_dev_addr[] = {
+  0x00, 0x0A, 0x35, 0x00, 0x00, 0x00
+};
+
 /* PCI id for devices */
 static const struct pci_device_id onic_pci_ids[] = {
-	{ PCI_DEVICE(0x10ee, 0x903f) },
-	{ PCI_DEVICE(0x10ee, 0x913f) },
-	{ PCI_DEVICE(0x10ee, 0x923f) },
-	{ PCI_DEVICE(0x10ee, 0x933f) },
-	{0}
+  { PCI_DEVICE(0x10ee, 0x9048) },
+  { PCI_DEVICE(0x10ee, 0x9148) },
+  { PCI_DEVICE(0x10ee, 0x9248) },
+  { PCI_DEVICE(0x10ee, 0x9348) },
+  { PCI_DEVICE(0x10ee, 0x903f) },
+  { PCI_DEVICE(0x10ee, 0x913f) },
+  { PCI_DEVICE(0x10ee, 0x923f) },
+  { PCI_DEVICE(0x10ee, 0x933f) },
+  {0}
 };
 MODULE_DEVICE_TABLE(pci, onic_pci_ids);
 
 static int onic_stats_alloc(struct onic_priv *xpriv)
 {
-	if (!xpriv) {
-		pr_err("%s: xpriv is NULL\n", __func__);
-		return -EINVAL;
-	}
-	if (!xpriv->netdev) {
-		pr_err("%s: xpriv->netdev is NULL\n", __func__);
-		return -EINVAL;
-	}
-
-	xpriv->tx_qstats = kcalloc(1,
-				   (xpriv->netdev->real_num_tx_queues *
-				    sizeof(struct rtnl_link_stats64)) +
-				   (xpriv->netdev->real_num_rx_queues *
-				    sizeof(struct rtnl_link_stats64))
-				   , GFP_KERNEL);
-
-	if (!xpriv->tx_qstats) {
-		netdev_err(xpriv->netdev, "%s: Memory allocation failure for stats\n",
-			   __func__);
-		return -ENOMEM;
-	}
-
-	xpriv->rx_qstats = xpriv->tx_qstats + xpriv->netdev->real_num_tx_queues;
-
-	return 0;
+  if (!xpriv) {
+    pr_err("%s: xpriv is NULL\n", __func__);
+    return -EINVAL;
+  }
+  if (!xpriv->netdev) {
+    pr_err("%s: xpriv->netdev is NULL\n", __func__);
+    return -EINVAL;
+  }
+
+  xpriv->tx_qstats = kcalloc(1,
+           (xpriv->netdev->real_num_tx_queues *
+            sizeof(struct rtnl_link_stats64)) +
+           (xpriv->netdev->real_num_rx_queues *
+            sizeof(struct rtnl_link_stats64))
+           , GFP_KERNEL);
+
+  printk(KERN_INFO "real_num_tx_queues: %d real_num_rx_queues %d\n", xpriv->netdev->real_num_tx_queues, xpriv->netdev->real_num_rx_queues);
+
+  if (!xpriv->tx_qstats) {
+    netdev_err(xpriv->netdev, "%s: Memory allocation failure for stats\n",
+         __func__);
+    return -ENOMEM;
+  }
+
+  xpriv->rx_qstats = xpriv->tx_qstats + xpriv->netdev->real_num_tx_queues;
+
+  return 0;
 }
 
 /* This function creates skb and moves data from dma request to network domain */
 static int onic_rx_deliver(struct onic_priv *xpriv, u32 q_no, unsigned int len,
-			   unsigned int sgcnt, struct qdma_sw_sg *sgl, void *udd)
+         unsigned int sgcnt, struct qdma_sw_sg *sgl, void *udd)
 {
-	struct net_device *netdev = xpriv->netdev;
-	struct sk_buff *skb = NULL;
-	struct qdma_sw_sg *c2h_sgl = sgl;
-
-	if (!sgcnt) {
-		netdev_err(netdev, "%s: SG Count is NULL\n", __func__);
-		return -EINVAL;
-	}
-	if (!sgl) {
-		netdev_err(netdev, "%s: SG List is NULL\n", __func__);
-		return -EINVAL;
-	}
-
-	if (len <= ONIC_RX_COPY_THRES || !(netdev->features & NETIF_F_SG)) {
-		skb = napi_alloc_skb(&xpriv->napi[q_no], len);
-		if (unlikely(!skb)) {
-			netdev_err(netdev, "%s: napi_alloc_skb() failed\n",
-				   __func__);
-			return -ENOMEM;
-		}
-
-		skb_copy_to_linear_data(skb, page_address(c2h_sgl->pg) +
-					c2h_sgl->offset, len);
-		__skb_put(skb, len);
-		put_page(c2h_sgl->pg);
-	} else {
-		unsigned int nr_frags = 0;
-		unsigned int frag_len;
-		unsigned int frag_offset;
-
-		/* Main body length for sk_buffs used for Rx Ethernet packets
-		 * with fragments. Should be >= ONIC_RX_PULL_LEN
-		 */
-		skb = napi_alloc_skb(&xpriv->napi[q_no], ONIC_RX_PULL_LEN);
-		if (unlikely(!skb)) {
-			netdev_err(netdev, "%s: napi_alloc_skb() failed\n",
-				   __func__);
-			return -ENOMEM;
-		}
-
-		skb_copy_to_linear_data(skb,
-					page_address(c2h_sgl->pg) + c2h_sgl->offset,
-					ONIC_RX_PULL_LEN);
-		__skb_put(skb, ONIC_RX_PULL_LEN);
-
-		c2h_sgl->offset += ONIC_RX_PULL_LEN;
-		c2h_sgl->len -= ONIC_RX_PULL_LEN;
-
-		while (sgcnt && c2h_sgl) {
-			frag_len = c2h_sgl->len;
-			frag_offset = c2h_sgl->offset;
-			skb_fill_page_desc(skb, nr_frags, c2h_sgl->pg, 
-					   frag_offset, frag_len);
-
-			sgcnt--;
-			c2h_sgl = c2h_sgl->next;
-			nr_frags++;
-		}
-
-		skb->len = len;
-		skb->data_len = len - ONIC_RX_PULL_LEN;
-		skb->truesize += skb->data_len;
-	}
-
-	skb->protocol = eth_type_trans(skb, netdev);
-	skb->ip_summed = CHECKSUM_NONE;
-	skb_record_rx_queue(skb, q_no);
-
-	skb_mark_napi_id(skb, &xpriv->napi[q_no]);
-	netif_receive_skb(skb);
-
-	return 0;
+  struct net_device *netdev = xpriv->netdev;
+  struct sk_buff *skb = NULL;
+  struct qdma_sw_sg *c2h_sgl = sgl;
+
+  if (!sgcnt) {
+    netdev_err(netdev, "%s: SG Count is NULL\n", __func__);
+    return -EINVAL;
+  }
+  if (!sgl) {
+    netdev_err(netdev, "%s: SG List is NULL\n", __func__);
+    return -EINVAL;
+  }
+
+  if (len <= ONIC_RX_COPY_THRES || !(netdev->features & NETIF_F_SG)) {
+    skb = napi_alloc_skb(&xpriv->napi[q_no], len);
+    if (unlikely(!skb)) {
+      netdev_err(netdev, "%s: napi_alloc_skb() failed\n",
+           __func__);
+      return -ENOMEM;
+    }
+
+    skb_copy_to_linear_data(skb, page_address(c2h_sgl->pg) +
+          c2h_sgl->offset, len);
+    __skb_put(skb, len);
+    put_page(c2h_sgl->pg);
+  } else {
+    unsigned int nr_frags = 0;
+    unsigned int frag_len;
+    unsigned int frag_offset;
+
+    /* Main body length for sk_buffs used for Rx Ethernet packets
+     * with fragments. Should be >= ONIC_RX_PULL_LEN
+     */
+    skb = napi_alloc_skb(&xpriv->napi[q_no], ONIC_RX_PULL_LEN);
+    if (unlikely(!skb)) {
+      netdev_err(netdev, "%s: napi_alloc_skb() failed\n",
+           __func__);
+      return -ENOMEM;
+    }
+
+    skb_copy_to_linear_data(skb,
+          page_address(c2h_sgl->pg) + c2h_sgl->offset,
+          ONIC_RX_PULL_LEN);
+    __skb_put(skb, ONIC_RX_PULL_LEN);
+
+    c2h_sgl->offset += ONIC_RX_PULL_LEN;
+    c2h_sgl->len -= ONIC_RX_PULL_LEN;
+
+    while (sgcnt && c2h_sgl) {
+      frag_len = c2h_sgl->len;
+      frag_offset = c2h_sgl->offset;
+      skb_fill_page_desc(skb, nr_frags, c2h_sgl->pg,
+             frag_offset, frag_len);
+
+      sgcnt--;
+      c2h_sgl = c2h_sgl->next;
+      nr_frags++;
+    }
+
+    skb->len = len;
+    skb->data_len = len - ONIC_RX_PULL_LEN;
+    skb->truesize += skb->data_len;
+  }
+
+  skb->protocol = eth_type_trans(skb, netdev);
+  skb->ip_summed = CHECKSUM_NONE;
+  skb_record_rx_queue(skb, q_no);
+
+  skb_mark_napi_id(skb, &xpriv->napi[q_no]);
+  netif_receive_skb(skb);
+
+  return 0;
 }
 
 /* This function process RX dma request */
 static int onic_rx_pkt_process(unsigned long qhndl, unsigned long quld,
-			       unsigned int len, unsigned int sgcnt,
-			       struct qdma_sw_sg *sgl, void *udd)
+             unsigned int len, unsigned int sgcnt,
+             struct qdma_sw_sg *sgl, void *udd)
 {
-	u32 q_no;
-	int ret = 0;
-	struct qdma_sw_sg *l_sgl = sgl;
-	struct onic_priv *xpriv = (struct onic_priv *)quld;
-	struct net_device *netdev = xpriv->netdev;
-
-	if (!netdev) {
-		pr_err("%s: netdev is NULL\n", __func__);
-		return -EINVAL;
-	}
-
-	if (!xpriv) {
-		pr_err("%s: xpriv is NULL\n", __func__);
-		return -EINVAL;
-	}
-
-	if (!sgcnt) {
-		netdev_err(netdev, "%s: SG Count is zero\n", __func__);
-		return -EINVAL;
-	}
-
-	q_no = (qhndl - xpriv->base_rx_q_handle);
-	ret = onic_rx_deliver(xpriv, q_no, len, sgcnt, sgl, udd);
-	if (ret < 0) {
-		while (sgcnt) {
-			put_page(l_sgl->pg);
-			l_sgl = l_sgl->next;
-			sgcnt--;
-		}
-	}
-
-	xpriv->rx_qstats[q_no].rx_packets++;
-	xpriv->rx_qstats[q_no].rx_bytes += len;
-
-	netdev_dbg(xpriv->netdev,
-		   "%s: q_no = %u, qhndl = %lu, len = %d processed\n", __func__,
-		   q_no, qhndl, len);
-
-	return ret;
+  u32 q_no;
+  int ret = 0;
+  struct qdma_sw_sg *l_sgl = sgl;
+  struct onic_priv *xpriv = (struct onic_priv *)quld;
+  struct net_device *netdev = xpriv->netdev;
+
+  if (!netdev) {
+    pr_err("%s: netdev is NULL\n", __func__);
+    return -EINVAL;
+  }
+
+  if (!xpriv) {
+    pr_err("%s: xpriv is NULL\n", __func__);
+    return -EINVAL;
+  }
+
+  if (!sgcnt) {
+    netdev_err(netdev, "%s: SG Count is zero\n", __func__);
+    return -EINVAL;
+  }
+
+  q_no = (qhndl - xpriv->base_rx_q_handle);
+
+  if(q_no >= QDMA_NET_QUEUE) {
+    // Igonre non-networking requests
+    //pr_info("%s q_no = %d, qhndl = %ld, xpriv->base_rx_q_handle=%ld\n", __func__, q_no, qhndl, xpriv->base_rx_q_handle);
+    return ret;
+  }
+
+  ret = onic_rx_deliver(xpriv, q_no, len, sgcnt, sgl, udd);
+  if (ret < 0) {
+    while (sgcnt) {
+      put_page(l_sgl->pg);
+      l_sgl = l_sgl->next;
+      sgcnt--;
+    }
+  }
+
+  xpriv->rx_qstats[q_no].rx_packets++;
+  xpriv->rx_qstats[q_no].rx_bytes += len;
+
+  netdev_dbg(xpriv->netdev,
+       "%s: q_no = %u, qhndl = %lu, len = %d processed\n", __func__,
+       q_no, qhndl, len);
+
+  return ret;
 }
 
 /* This is deffered NAPI task for processing incoming Rx packet from DMA queue
@@ -183,170 +205,222 @@ static int onic_rx_pkt_process(unsigned long qhndl, unsigned long quld,
  */
 static int onic_rx_poll(struct napi_struct *napi, int quota)
 {
-	int queue_id;
-	unsigned long q_handle;
-	unsigned int udd_cnt = 0, pkt_cnt = 0, data_len = 0;
-	struct onic_priv *xpriv;
-	struct net_device *netdev;
-	int ret;
-
-	if (unlikely(!napi)) {
-		pr_err("%s: Invalid NAPI\n", __func__);
-		return -EINVAL;
-	}
-
-	netdev = napi->dev;
-	if (unlikely(!netdev)) {
-		pr_err("%s: netdev is NULL\n", __func__);
-		return -EINVAL;
-	}
-
-	xpriv = netdev_priv(netdev);
-	if (unlikely(!xpriv)) {
-		pr_err("%s: xpriv is NULL\n", __func__);
-		return -EINVAL;
-	}
-
-	queue_id = (int)(napi - xpriv->napi);
-	q_handle = (xpriv->base_rx_q_handle + queue_id);
-
-	/* Call queue service for QDMA Core to service queue */
-	ret = qdma_queue_service(xpriv->dev_handle, q_handle, quota, true);
-	/* Indicate napi_complete irrespective of ret */
-	napi_complete(napi);
-	if (!xpriv->pinfo->poll_mode && ret < 0) {
-		netdev_dbg(netdev, "%s: qdma_queue_service for queue=%d returned status=%d\n",
-			   __func__, queue_id, ret);
-		return ret;
-	}
-
-	if (xpriv->qdma_dev_conf.intr_moderation)
-		qdma_queue_c2h_peek(xpriv->dev_handle, q_handle, &udd_cnt,
-				    &pkt_cnt, &data_len);
-
-	qdma_queue_update_pointers(xpriv->dev_handle, q_handle);
-
-	if (xpriv->pinfo->poll_mode || (pkt_cnt >= quota))
-		napi_reschedule(napi);
-
-	return 0;
+  int queue_id;
+  unsigned long q_handle;
+  unsigned int udd_cnt = 0, pkt_cnt = 0, data_len = 0;
+  struct onic_priv *xpriv;
+  struct net_device *netdev;
+  int ret;
+
+  if (unlikely(!napi)) {
+    pr_err("%s: Invalid NAPI\n", __func__);
+    return -EINVAL;
+  }
+
+  netdev = napi->dev;
+  if (unlikely(!netdev)) {
+    pr_err("%s: netdev is NULL\n", __func__);
+    return -EINVAL;
+  }
+
+  xpriv = netdev_priv(netdev);
+  if (unlikely(!xpriv)) {
+    pr_err("%s: xpriv is NULL\n", __func__);
+    return -EINVAL;
+  }
+
+  queue_id = (int)(napi - xpriv->napi);
+  q_handle = (xpriv->base_rx_q_handle + queue_id);
+
+  /* Call queue service for QDMA Core to service queue */
+  ret = qdma_queue_service(xpriv->dev_handle, q_handle, quota, true);
+  /* Indicate napi_complete irrespective of ret */
+  napi_complete(napi);
+  if (!xpriv->pinfo->poll_mode && ret < 0) {
+    netdev_dbg(netdev, "%s: qdma_queue_service for queue=%d returned status=%d\n",
+         __func__, queue_id, ret);
+    return ret;
+  }
+
+  if (xpriv->qdma_dev_conf.intr_moderation)
+    qdma_queue_c2h_peek(xpriv->dev_handle, q_handle, &udd_cnt,
+            &pkt_cnt, &data_len);
+
+  //qdma_queue_update_pointers(xpriv->dev_handle, q_handle);
+  // memory-mapped queues do not use this
+  if(queue_id < QDMA_NET_QUEUE) qdma_queue_update_pointers(xpriv->dev_handle, q_handle);
+
+  if (xpriv->pinfo->poll_mode || (pkt_cnt >= quota))
+    napi_reschedule(napi);
+
+  return 0;
 }
 
 /* This function is RX interrupt handler (TOP half) */
 static void onic_isr_rx_tophalf(unsigned long qhndl, unsigned long uld)
 {
-	u32 q_no;
-	struct onic_priv *xpriv = (struct onic_priv *)uld;
+  u32 q_no;
+  struct onic_priv *xpriv = (struct onic_priv *)uld;
 
-	/* ISR is for Rx queue */
-	q_no = (qhndl - xpriv->base_rx_q_handle);
+  /* ISR is for Rx queue */
+  q_no = (qhndl - xpriv->base_rx_q_handle);
 
-	napi_schedule_irqoff(&xpriv->napi[q_no]);
+  if(q_no < QDMA_NET_QUEUE) {
+    napi_schedule_irqoff(&xpriv->napi[q_no]);
+  } else {
+    //pr_info("%s q_no = %d, qhndl = %ld, xpriv->base_rx_q_handle=%ld\n", __func__, q_no, qhndl, xpriv->base_rx_q_handle);
+  }
 
-	netdev_dbg(xpriv->netdev, "%s: Rx interrupt called. Mapped queue no = %d\n",
-		   __func__, q_no);
+  netdev_dbg(xpriv->netdev, "%s: Rx interrupt called. Mapped queue no = %d\n",
+       __func__, q_no);
 }
 
 /* Add a RX queue to QDMA */
 static int onic_qdma_rx_queue_add(struct onic_priv *xpriv, u32 q_no,
-				  u8 timer_idx, u8 cnt_th_idx)
+          u8 timer_idx, u8 cnt_th_idx, int is_streaming)
 {
-	int ret = 0;
-	char error_str[ONIC_ERROR_STR_BUF_LEN] = { '0' };
-	unsigned long q_handle = 0;
-	struct qdma_queue_conf qconf;
-
-	memset(&qconf, 0, sizeof(struct qdma_queue_conf));
-	qconf.st = 1;
-	qconf.q_type = Q_C2H;
-	qconf.irq_en = 0;
-	qconf.pfetch_en = 1;
-	qconf.fetch_credit = 1;
-	qconf.cmpl_stat_en = 1;
-	qconf.cmpl_desc_sz = DESC_SZ_8B;
-	qconf.cmpl_rng_sz_idx = xpriv->cmpl_rng_sz_idx;
-	qconf.desc_rng_sz_idx = xpriv->rx_desc_rng_sz_idx;
-	qconf.c2h_buf_sz_idx = xpriv->rx_buf_sz_idx;
-	qconf.cmpl_timer_idx = timer_idx;
-	qconf.cmpl_cnt_th_idx = cnt_th_idx;
-	qconf.cmpl_trig_mode = TRIG_MODE_COMBO;
-	qconf.cmpl_en_intr = (xpriv->pinfo->poll_mode == 0);
-	qconf.quld = (unsigned long)xpriv;
-	qconf.fp_descq_isr_top = onic_isr_rx_tophalf;
-	qconf.fp_descq_c2h_packet = onic_rx_pkt_process;
-
-	netdev_dbg(xpriv->netdev,
-		   "%s: c2h_rng_sz_idx = %d, desc_rng_sz_idx = %d, c2h_buf_sz_idx = %d, c2h_timer_idx = %d, c2h_cnt_th_idx = %d\n",
-		   __func__, qconf.cmpl_rng_sz_idx, qconf.desc_rng_sz_idx,
-		   qconf.c2h_buf_sz_idx, qconf.cmpl_timer_idx,
-		   qconf.cmpl_cnt_th_idx);
-
-	qconf.qidx = q_no;
-	ret = qdma_queue_add(xpriv->dev_handle, &qconf, &q_handle, error_str,
-			     ONIC_ERROR_STR_BUF_LEN);
-	if (ret != 0) {
-		netdev_err(xpriv->netdev,
-			   "%s: qdma_queue_add() failed for queue %d with status %d(%s)\n",
-			   __func__, qconf.qidx, ret, error_str);
-		return ret;
-	}
-
-	/* Get base q_handle */
-	if (q_no == 0)
-		xpriv->base_rx_q_handle = q_handle;
-
-	return 0;
+  int ret = 0;
+  char error_str[ONIC_ERROR_STR_BUF_LEN] = { '0' };
+  unsigned long q_handle = 0;
+  struct qdma_queue_conf qconf;
+
+  memset(&qconf, 0, sizeof(struct qdma_queue_conf));
+  qconf.st = q_no >= QDMA_NET_QUEUE ? 0 : 1;
+  qconf.q_type = Q_C2H;
+  qconf.irq_en = (xpriv->pinfo->poll_mode == 0);
+  qconf.pfetch_en = 1;
+  qconf.fetch_credit = 1;
+  qconf.cmpl_stat_en = 1;
+  qconf.wb_status_en = q_no >= QDMA_NET_QUEUE ? 1 : 0;
+  qconf.cmpl_desc_sz = DESC_SZ_8B;
+  qconf.cmpl_rng_sz_idx = xpriv->cmpl_rng_sz_idx;
+  qconf.desc_rng_sz_idx = xpriv->rx_desc_rng_sz_idx;
+  qconf.c2h_buf_sz_idx = xpriv->rx_buf_sz_idx;
+  qconf.cmpl_timer_idx = timer_idx;
+  qconf.cmpl_cnt_th_idx = cnt_th_idx;
+  qconf.cmpl_trig_mode = TRIG_MODE_COMBO;
+  qconf.cmpl_en_intr = (xpriv->pinfo->poll_mode == 0);
+  qconf.quld = (unsigned long)xpriv;
+  if( q_no < QDMA_NET_QUEUE ) {
+    qconf.fp_descq_isr_top = onic_isr_rx_tophalf;
+  }
+  qconf.fp_descq_c2h_packet = onic_rx_pkt_process;
+  /*
+  if( q_no < QDMA_NET_QUEUE ) {
+    qconf.fp_descq_isr_top = onic_isr_rx_tophalf;
+    qconf.fp_descq_c2h_packet = onic_rx_pkt_process;
+  }
+  */
+
+  netdev_dbg(xpriv->netdev,
+       "%s: c2h_rng_sz_idx = %d, desc_rng_sz_idx = %d, c2h_buf_sz_idx = %d, c2h_timer_idx = %d, c2h_cnt_th_idx = %d\n",
+       __func__, qconf.cmpl_rng_sz_idx, qconf.desc_rng_sz_idx,
+       qconf.c2h_buf_sz_idx, qconf.cmpl_timer_idx,
+       qconf.cmpl_cnt_th_idx);
+
+  qconf.qidx = q_no;
+
+  ret = qdma_queue_add(xpriv->dev_handle, &qconf, &q_handle, error_str,
+           ONIC_ERROR_STR_BUF_LEN);
+  xpriv->pinfo->active_rx_queues++;
+  if (ret != 0) {
+    netdev_err(xpriv->netdev,
+         "%s: qdma_queue_add() failed for queue %d with status %d(%s)\n",
+         __func__, qconf.qidx, ret, error_str);
+    return ret;
+  }
+
+  /*
+  if (q_no >= QDMA_NET_QUEUE) {
+    pr_info("%s q_no = %d, q_handle = %ld\n", __func__, q_no, q_handle);
+  }
+  */
+
+  /* Get base q_handle */
+  if (q_no == 0) {
+    xpriv->base_rx_q_handle = q_handle;
+  }
+
+  if (q_no == QDMA_NET_QUEUE){
+    xpriv->onic_cdev_ptr->mm_c2h_q_hndl = xpriv->base_rx_q_handle + QDMA_NET_QUEUE;
+  }
+
+  return 0;
 }
 
 /* This function releases Rx queues */
 static void onic_qdma_rx_queue_release(struct onic_priv *xpriv, int num_queues)
 {
-	int ret = 0, q_no = 0;
-	char error_str[ONIC_ERROR_STR_BUF_LEN] = { '0' };
-
-	for (q_no = 0; q_no < num_queues; q_no++) {
-		ret = qdma_queue_remove(xpriv->dev_handle,
-					(xpriv->base_rx_q_handle + q_no),
-					error_str, ONIC_ERROR_STR_BUF_LEN);
-		if (ret != 0) {
-			netdev_err(xpriv->netdev,
-				   "%s: qdma_queue remove() failed for queue %d with status %d(%s)\n",
-				   __func__, q_no, ret, error_str);
-		}
-		netif_napi_del(&xpriv->napi[q_no]);
-	}
-
-	kfree(xpriv->napi);
+  struct xlnx_dma_dev* xdev;
+  struct qdma_dev *qdev;
+	struct qdma_descq *descq;
+
+  int ret = 0, q_no = 0;
+  char error_str[ONIC_ERROR_STR_BUF_LEN] = { '0' };
+
+  xdev = (struct xlnx_dma_dev *) xpriv->dev_handle;
+  qdev = xdev_2_qdev(xdev);
+
+  for (q_no = 0, descq = qdev->c2h_descq; q_no < num_queues; q_no++, descq++) {
+    if (descq->q_state == Q_STATE_ENABLED) {
+      ret = qdma_queue_remove(xpriv->dev_handle,
+            (xpriv->base_rx_q_handle + q_no),
+            error_str, ONIC_ERROR_STR_BUF_LEN);
+      if (ret != 0) {
+        netdev_err(xpriv->netdev,
+            "%s: qdma_queue remove() failed for queue %d with status %d(%s)\n",
+            __func__, q_no, ret, error_str);
+      }
+    }
+    if (q_no < QDMA_NET_QUEUE) {
+      netif_napi_del(&xpriv->napi[q_no]);
+    }
+  }
+
+  kfree(xpriv->napi);
 }
 
 /* This function sets up RX queues */
 static int onic_qdma_rx_queue_setup(struct onic_priv *xpriv)
 {
-	int ret = 0, q_no = 0;
-
-	xpriv->napi = kcalloc(xpriv->netdev->real_num_rx_queues,
-			      sizeof(struct napi_struct), GFP_KERNEL);
-	if (!xpriv->napi) 
-		return -ENOMEM;
-
-	for (q_no = 0; q_no < xpriv->netdev->real_num_rx_queues; q_no++) {
-		ret = onic_qdma_rx_queue_add(xpriv, q_no, xpriv->rx_timer_idx,
-					     xpriv->rx_cnt_th_idx);
-		if (ret != 0) {
-			netdev_err(xpriv->netdev,
-				   "%s: onic_qdma_rx_queue_add() failed for queue %d with status %d\n",
-				   __func__, q_no, ret);
-			goto release_rx_q;
-		}
-		netif_napi_add(xpriv->netdev, &xpriv->napi[q_no], onic_rx_poll,
-			       ONIC_NAPI_WEIGHT);
-	}
-
-	return 0;
+  int ret = 0, q_no = 0;
+
+  xpriv->napi = kcalloc(xpriv->netdev->real_num_rx_queues,
+            sizeof(struct napi_struct), GFP_KERNEL);
+  if (!xpriv->napi)
+    return -ENOMEM;
+
+  for (q_no = 0; q_no < xpriv->netdev->real_num_rx_queues; q_no++) {
+    ret = onic_qdma_rx_queue_add(xpriv, q_no, xpriv->rx_timer_idx,
+               xpriv->rx_cnt_th_idx, 1);
+    if (ret != 0) {
+      netdev_err(xpriv->netdev,
+           "%s: onic_qdma_rx_queue_add() failed for queue %d with status %d\n",
+           __func__, q_no, ret);
+      goto release_rx_q;
+    }
+    netif_napi_add(xpriv->netdev, &xpriv->napi[q_no], onic_rx_poll,
+             ONIC_NAPI_WEIGHT);
+  }
+
+  // Add rx queue for QDMA AXI-MM channels
+  for (q_no = QDMA_NET_QUEUE; q_no < (QDMA_NET_QUEUE + xpriv->pinfo->mm_queues); q_no++) {
+    ret = onic_qdma_rx_queue_add(xpriv, q_no, xpriv->rx_timer_idx,
+               xpriv->rx_cnt_th_idx, 1);
+    if (ret != 0) {
+      netdev_err(xpriv->netdev,
+           "%s: onic_qdma_rx_queue_add() failed for queue %d with status %d\n",
+           __func__, q_no, ret);
+      goto release_rx_q;
+    }
+  }
+
+  return 0;
 
 release_rx_q:
-	onic_qdma_rx_queue_release(xpriv, q_no);
-	return ret;
+  //onic_qdma_rx_queue_release(xpriv, q_no);
+  onic_qdma_rx_queue_release(xpriv, xpriv->pinfo->active_rx_queues);
+  return ret;
 }
 
 /* This function is interrupt handler (TOP half).
@@ -355,150 +429,176 @@ release_rx_q:
  */
 static void onic_isr_tx_tophalf(unsigned long qhndl, unsigned long uld)
 {
-	u32 q_no;
-	struct onic_priv *xpriv = (struct onic_priv *)uld;
-	struct xlnx_dma_dev *xdev = (struct xlnx_dma_dev *)xpriv->dev_handle;
-	struct qdma_descq *descq = qdma_device_get_descq_by_id(xdev, qhndl,
-							       NULL, 0, 0);
-
-	schedule_work(&descq->work);
-
-	/* If ISR is for Tx queue */
-	q_no = (qhndl - xpriv->base_tx_q_handle);
-	netdev_dbg(xpriv->netdev, "%s: Tx interrupt called, Mapped queue no = %d\n",
-		   __func__, q_no);
+  u32 q_no;
+  struct onic_priv *xpriv = (struct onic_priv *)uld;
+  struct xlnx_dma_dev *xdev = (struct xlnx_dma_dev *)xpriv->dev_handle;
+  struct qdma_descq *descq = qdma_device_get_descq_by_id(xdev, qhndl,
+                     NULL, 0, 0);
+
+  schedule_work(&descq->work);
+
+  /* If ISR is for Tx queue */
+  q_no = (qhndl - xpriv->base_tx_q_handle);
+
+  netdev_dbg(xpriv->netdev, "%s: Tx interrupt called, Mapped queue no = %d\n",
+       __func__, q_no);
 }
 
 /* This function release Tx queues */
 static void onic_qdma_tx_queue_release(struct onic_priv *xpriv, int num_queues)
 {
-	int ret = 0, q_no = 0;
-	char error_str[ONIC_ERROR_STR_BUF_LEN] = { '0' };
-
-	for (q_no = 0; q_no < num_queues; q_no++) {
-		ret = qdma_queue_remove(xpriv->dev_handle,
-					(xpriv->base_tx_q_handle + q_no),
-					error_str, ONIC_ERROR_STR_BUF_LEN);
-		if (ret != 0) {
-			netdev_err(xpriv->netdev,
-				   "%s: qdma_queue_remove() failed for queue %d with status %d(%s)\n",
-				   __func__, q_no, ret, error_str);
-		}
-
-	}
+  struct xlnx_dma_dev* xdev;
+  struct qdma_dev *qdev;
+	struct qdma_descq *descq;
+
+  int ret = 0, q_no = 0;
+  char error_str[ONIC_ERROR_STR_BUF_LEN] = { '0' };
+
+  xdev = (struct xlnx_dma_dev *) xpriv->dev_handle;
+  qdev = xdev_2_qdev(xdev);
+
+  for (q_no = 0, descq = qdev->h2c_descq; q_no < num_queues; q_no++, descq++) {
+    if (descq->q_state == Q_STATE_ENABLED) {
+      ret = qdma_queue_remove(xpriv->dev_handle,
+            (xpriv->base_tx_q_handle + q_no),
+            error_str, ONIC_ERROR_STR_BUF_LEN);
+      if (ret != 0) {
+        netdev_err(xpriv->netdev,
+            "%s: qdma_queue_remove() failed for queue %d with status %d(%s)\n",
+            __func__, q_no, ret, error_str);
+      }
+    }
+  }
 }
 
 /* This function sets up Tx queues */
 static int onic_qdma_tx_queue_setup(struct onic_priv *xpriv)
 {
-	int ret = 0, q_no = 0;
-	char error_str[ONIC_ERROR_STR_BUF_LEN] = { '0' };
-	unsigned long q_handle = 0;
-	struct qdma_queue_conf qconf;
-
-	for (q_no = 0; q_no < xpriv->netdev->real_num_tx_queues; q_no++) {
-		memset(&qconf, 0, sizeof(struct qdma_queue_conf));
-		qconf.st = 1;
-		qconf.q_type = Q_H2C;
-		qconf.irq_en = (xpriv->pinfo->poll_mode == 0);
-		qconf.wb_status_en = 1;
-		qconf.cmpl_stat_en = 1;
-		qconf.cmpl_status_acc_en = 1;
-		qconf.cmpl_status_pend_chk = 1;
-		qconf.desc_rng_sz_idx = xpriv->tx_desc_rng_sz_idx;
-		qconf.fp_descq_isr_top = onic_isr_tx_tophalf;
-		qconf.quld = (unsigned long)xpriv;
-		qconf.qidx = q_no;
-
-		ret = qdma_queue_add(xpriv->dev_handle, &qconf, &q_handle,
-				     error_str, ONIC_ERROR_STR_BUF_LEN);
-
-		if (ret != 0) {
-			netdev_err(xpriv->netdev, 
-				   "%s: qdma_queue_add() failed for queue %d with status %d(%s)\n",
-				   __func__, qconf.qidx, ret, error_str);
-			goto cleanup_tx_q;
-		}
-		if (q_no == 0)
-			xpriv->base_tx_q_handle = q_handle;
-
-	}
-	return 0;
+  int ret = 0, q_no = 0;
+  char error_str[ONIC_ERROR_STR_BUF_LEN] = { '0' };
+  unsigned long q_handle = 0;
+  struct qdma_queue_conf qconf;
+
+  for (q_no = 0; q_no < (xpriv->netdev->real_num_tx_queues + xpriv->pinfo->mm_queues); q_no++) {
+    memset(&qconf, 0, sizeof(struct qdma_queue_conf));
+    qconf.st = (q_no >= QDMA_NET_QUEUE) ? 0 : 1;
+    qconf.q_type = Q_H2C;
+    qconf.irq_en = (xpriv->pinfo->poll_mode == 0);
+    qconf.wb_status_en = 1;
+    qconf.cmpl_stat_en = 1;
+    qconf.cmpl_status_acc_en = 1;
+    qconf.cmpl_status_pend_chk = 1;
+    qconf.desc_rng_sz_idx = xpriv->tx_desc_rng_sz_idx;
+    qconf.quld = (unsigned long)xpriv;
+    qconf.qidx = q_no;
+    qconf.fp_descq_isr_top = onic_isr_tx_tophalf;
+    /*
+    if( q_no < QDMA_NET_QUEUE ) {
+      qconf.fp_descq_isr_top = onic_isr_tx_tophalf;
+    }
+    */
+
+    ret = qdma_queue_add(xpriv->dev_handle, &qconf, &q_handle,
+             error_str, ONIC_ERROR_STR_BUF_LEN);
+
+    xpriv->pinfo->active_tx_queues++;
+    if (ret != 0) {
+      netdev_err(xpriv->netdev,
+           "%s: qdma_queue_add() failed for queue %d with status %d(%s)\n",
+           __func__, qconf.qidx, ret, error_str);
+      goto cleanup_tx_q;
+    }
+    if (q_no == 0)
+      xpriv->base_tx_q_handle = q_handle;
+    if (q_no == QDMA_NET_QUEUE)
+      xpriv->onic_cdev_ptr->mm_h2c_q_hndl = xpriv->base_tx_q_handle + QDMA_NET_QUEUE;
+  }
+  return 0;
 
 cleanup_tx_q:
-	onic_qdma_tx_queue_release(xpriv, q_no);
-	return ret;
+  onic_qdma_tx_queue_release(xpriv, xpriv->pinfo->active_tx_queues);
+  return ret;
 }
 
 
 /* This function stops Tx and Rx queues operations */
 static int onic_qdma_stop(struct onic_priv *xpriv, unsigned short int txq,
-			  unsigned short int rxq)
+        unsigned short int rxq)
 {
-	int ret = 0, q = 0, err = 0;
-	char error_str[ONIC_ERROR_STR_BUF_LEN] = { '0' };
-
-	for (q = 0; q < rxq; q++) {
-		ret = qdma_queue_stop(xpriv->dev_handle,
-				      xpriv->base_rx_q_handle + q, error_str,
-				      ONIC_ERROR_STR_BUF_LEN);
-		if (ret < 0) {
-			netdev_err(xpriv->netdev,
-				   "%s: qdma_queue_stop() failed for Rx queue %d with status %d msg: %s\n",
-				   __func__, q, ret, error_str);
-			err = -EINVAL;
-		}
-	}
-
-	for (q = 0; q < txq; q++) {
-		ret = qdma_queue_stop(xpriv->dev_handle,
-				      xpriv->base_tx_q_handle + q, error_str,
-				      ONIC_ERROR_STR_BUF_LEN);
-		if (ret < 0) {
-			netdev_err(xpriv->netdev,
-				   "%s: qdma_queue_stop() failed for Tx queue %d with status %d msg: %s\n",
-				   __func__, q, ret, error_str);
-			err = -EINVAL;
-		}
-	}
-
-	return err;
+  int ret = 0, q = 0, err = 0;
+  struct xlnx_dma_dev* xdev;
+  struct qdma_dev *qdev;
+	struct qdma_descq *descq;
+
+  char error_str[ONIC_ERROR_STR_BUF_LEN] = { '0' };
+
+  xdev = (struct xlnx_dma_dev *) xpriv->dev_handle;
+  qdev = xdev_2_qdev(xdev);
+
+  for (q = 0, descq = qdev->c2h_descq; q < rxq; q++, descq++) {
+    if(descq->q_state == Q_STATE_ONLINE) {
+      ret = qdma_queue_stop(xpriv->dev_handle,
+                xpriv->base_rx_q_handle + q, error_str,
+                ONIC_ERROR_STR_BUF_LEN);
+      if (ret < 0) {
+        netdev_err(xpriv->netdev,
+            "%s: qdma_queue_stop() failed for Rx queue %d with status %d msg: %s\n",
+            __func__, q, ret, error_str);
+        err = -EINVAL;
+      }
+    }
+  }
+
+  for (q = 0, descq = qdev->h2c_descq; q < txq; q++, descq++) {
+    if(descq->q_state == Q_STATE_ONLINE) {
+      ret = qdma_queue_stop(xpriv->dev_handle,
+                xpriv->base_tx_q_handle + q, error_str,
+                ONIC_ERROR_STR_BUF_LEN);
+      if (ret < 0) {
+        netdev_err(xpriv->netdev,
+            "%s: qdma_queue_stop() failed for Tx queue %d with status %d msg: %s\n",
+            __func__, q, ret, error_str);
+        err = -EINVAL;
+      }
+    }
+  }
+
+  return err;
 }
 
 /* This function starts Rx and Tx queues operations */
 static int onic_qdma_start(struct onic_priv *xpriv)
 {
-	int ret, q_no;
-	char error_str[ONIC_ERROR_STR_BUF_LEN] = { '0' };
-
-
-	for (q_no = 0; q_no < xpriv->netdev->real_num_rx_queues; q_no++) {
-		ret = qdma_queue_start(xpriv->dev_handle,
-				       xpriv->base_rx_q_handle + q_no,
-				       error_str, ONIC_ERROR_STR_BUF_LEN);
-		if (ret != 0) {
-			netdev_err(xpriv->netdev,
-				   "%s: qdma_queue_start() failed for Rx queue %d with status %d(%s)\n",
-				   __func__, q_no, ret, error_str);
-			onic_qdma_stop(xpriv, 0, q_no);
-			return ret;
-		}
-	}
-
-	for (q_no = 0; q_no < xpriv->netdev->real_num_tx_queues; q_no++) {
-		ret = qdma_queue_start(xpriv->dev_handle,
-				       xpriv->base_tx_q_handle + q_no,
-				       error_str, ONIC_ERROR_STR_BUF_LEN);
-		if (ret != 0) {
-			netdev_err(xpriv->netdev,
-				   "%s: qdma_queue_start() failed for Tx queue %d with status %d(%s)\n",
-				   __func__, q_no, ret, error_str);
-			onic_qdma_stop(xpriv, q_no, xpriv->netdev->real_num_rx_queues);
-			return ret;
-		}
-	}
-
-	return 0;
+  int ret, q_no;
+  char error_str[ONIC_ERROR_STR_BUF_LEN] = { '0' };
+
+  for (q_no = 0; q_no < xpriv->pinfo->active_rx_queues; q_no++) {
+    ret = qdma_queue_start(xpriv->dev_handle,
+              xpriv->base_rx_q_handle + q_no,
+              error_str, ONIC_ERROR_STR_BUF_LEN);
+    if (ret != 0) {
+      netdev_err(xpriv->netdev,
+          "%s: qdma_queue_start() failed for Rx queue %d with status %d(%s)\n",
+          __func__, q_no, ret, error_str);
+      onic_qdma_stop(xpriv, 0, xpriv->pinfo->active_rx_queues);
+      return ret;
+    }
+  }
+
+  for (q_no = 0; q_no < xpriv->pinfo->active_tx_queues; q_no++) {
+    ret = qdma_queue_start(xpriv->dev_handle,
+              xpriv->base_tx_q_handle + q_no,
+              error_str, ONIC_ERROR_STR_BUF_LEN);
+    if (ret != 0) {
+      netdev_err(xpriv->netdev,
+          "%s: qdma_queue_start() failed for Tx queue %d with status %d(%s)\n",
+          __func__, q_no, ret, error_str);
+      onic_qdma_stop(xpriv, xpriv->pinfo->active_tx_queues, 0);
+      return ret;
+    }
+  }
+
+  return 0;
 }
 
 /* This function gets called when interface gets 'UP' request via 'ifconfig up'
@@ -507,175 +607,148 @@ static int onic_qdma_start(struct onic_priv *xpriv)
  */
 int onic_open(struct net_device *netdev)
 {
-	int ret = 0, q_no = 0;
-	struct onic_priv * xpriv;
-
-	if (!netdev) {
-		pr_err("%s: netdev is NULL\n", __func__);
-		return -EINVAL;
-	}
-
-	xpriv = netdev_priv(netdev);
-	if (!xpriv) {
-		pr_err("%s: xpriv is NULL\n", __func__);
-		return -EINVAL;
-	}
-
-	ret = onic_stats_alloc(xpriv);
-	if (ret != 0) {
-		netdev_err(netdev,
-			   "%s: onic_stats_alloc() failed with status %d\n",
-			   __func__, ret);
-		return ret;
-	}
-
-	ret = onic_qdma_rx_queue_setup(xpriv);
-	if (ret != 0) {
-		netdev_err(netdev, "%s: onic_qdmx_rx_queue_setup() failed with status %d\n",
-			   __func__, ret);
-		kfree(xpriv->tx_qstats);
-		return ret;
-	}
-
-	ret = onic_qdma_tx_queue_setup(xpriv);
-	if (ret != 0) {
-		netdev_err(netdev, "%s: onic_qdmx_tx_queue_setup() failed with status %d\n",
-			   __func__, ret);
-		goto release_rx_queues;
-	}
-
-	ret = onic_qdma_start(xpriv);
-	if (ret != 0) {
-		netdev_err(netdev, "%s: onic_qdma_start() failed with status %d\n",
-			   __func__, ret);
-		goto release_queues;
-	}
-
-	for (q_no = 0; q_no < xpriv->netdev->real_num_rx_queues; q_no++)
-		napi_enable(&xpriv->napi[q_no]);
-
-	if (xpriv->pinfo->poll_mode)
-		for (q_no = 0; q_no < xpriv->netdev->real_num_rx_queues; q_no++)
-			napi_schedule(&xpriv->napi[q_no]);
-
-	netif_tx_start_all_queues(netdev);
-	netif_carrier_on(netdev);
-
-	netdev_info(netdev, "%s: device open done\n", __func__);
-
-	return 0;
+  int ret = 0, q_no = 0;
+  struct onic_priv * xpriv;
 
-release_queues:
-	onic_qdma_tx_queue_release(xpriv, xpriv->netdev->real_num_tx_queues);
-release_rx_queues:
-	onic_qdma_rx_queue_release(xpriv, xpriv->netdev->real_num_rx_queues);
-	return ret;
-}
+  if (!netdev) {
+    pr_err("%s: netdev is NULL\n", __func__);
+    return -EINVAL;
+  }
 
-/* This function gets called when there is a interface down request.
- * In this function, Tx/Rx operations on the queues are stopped
- */
-static int onic_stop(struct net_device *netdev)
-{
-	int ret = 0, q_no = 0;
-	struct onic_priv *xpriv;
+  xpriv = netdev_priv(netdev);
+  if (!xpriv) {
+    pr_err("%s: xpriv is NULL\n", __func__);
+    return -EINVAL;
+  }
+
+  onic_init_cdev(xpriv->onic_cdev_ptr, xpriv->onic_cdev_ptr->no_mm_queues);
 
-	if (!netdev) {
-		pr_err("%s: netdev is NULL\n", __func__);
-		return -EINVAL;
-	}
+  ret = onic_qdma_start(xpriv);
+  if (ret != 0) {
+    netdev_err(netdev, "%s: onic_qdma_start() failed with status %d\n",
+         __func__, ret);
+    goto release_queues;
+  }
 
-	xpriv = netdev_priv(netdev);
-	if (!xpriv) {
-		pr_err("%s: xpriv is NULL\n", __func__);
-		return -EINVAL;
-	}
+  for (q_no = 0; q_no < xpriv->netdev->real_num_rx_queues; q_no++)
+    napi_enable(&xpriv->napi[q_no]);
 
-	netif_tx_stop_all_queues(netdev);
-	netif_carrier_off(netdev);
+  if (xpriv->pinfo->poll_mode)
+    for (q_no = 0; q_no < xpriv->netdev->real_num_rx_queues; q_no++)
+      napi_schedule(&xpriv->napi[q_no]);
 
-	for (q_no = 0; q_no < xpriv->netdev->real_num_rx_queues; q_no++)
-		napi_disable(&xpriv->napi[q_no]);
+  netif_tx_start_all_queues(netdev);
+  netif_carrier_on(netdev);
 
-	ret = onic_qdma_stop(xpriv, netdev->real_num_tx_queues,
-			     netdev->real_num_rx_queues);
-	if (ret != 0)
-		netdev_err(netdev, "%s: onic_qdma_stop() failed with status %d\n",
-			   __func__, ret);
+  netdev_info(netdev, "%s: device open done\n", __func__);
 
-	onic_qdma_rx_queue_release(xpriv, netdev->real_num_rx_queues);
-	onic_qdma_tx_queue_release(xpriv, netdev->real_num_tx_queues);
+  return 0;
 
-	kfree(xpriv->tx_qstats);
+release_queues:
+  onic_qdma_tx_queue_release(xpriv, xpriv->pinfo->active_tx_queues);
+  onic_qdma_rx_queue_release(xpriv, xpriv->pinfo->active_rx_queues);
+  return ret;
+}
 
-	netdev_info(netdev, "%s: device close done\n", __func__);
-	return ret;
+/* This function gets called when there is a interface down request.
+ * In this function, Tx/Rx operations on the queues are stopped
+ */
+static int onic_stop(struct net_device *netdev)
+{
+  int ret = 0, q_no = 0;
+  struct onic_priv *xpriv;
+
+  if (!netdev) {
+    pr_err("%s: netdev is NULL\n", __func__);
+    return -EINVAL;
+  }
+
+  xpriv = netdev_priv(netdev);
+  if (!xpriv) {
+    pr_err("%s: xpriv is NULL\n", __func__);
+    return -EINVAL;
+  }
+  netif_tx_stop_all_queues(netdev);
+  netif_carrier_off(netdev);
+
+  for (q_no = 0; q_no < xpriv->netdev->real_num_rx_queues; q_no++)
+    napi_disable(&xpriv->napi[q_no]);
+
+  ret = onic_qdma_stop(xpriv, xpriv->pinfo->active_tx_queues,
+           xpriv->pinfo->active_rx_queues);
+
+  if (ret != 0)
+    netdev_err(netdev, "%s: onic_qdma_stop() failed with status %d\n",
+         __func__, ret);
+
+  netdev_info(netdev, "%s: device close done\n", __func__);
+  return ret;
 }
 
 /* This function free skb allocated memory */
 static int onic_unmap_free_pkt_data(struct qdma_request *req)
 {
-	u16 nb_frags = 0, frag_index = 0;
-	struct qdma_sw_sg *qdma_sgl;
-	struct onic_dma_request *onic_req;
-	struct net_device *netdev;
-	struct sk_buff *skb;
-	struct onic_priv *xpriv;
-	skb_frag_t *frag;
-
-	if (unlikely(!req)) {
-		pr_err("%s: req is NULL\n", __func__);
-		return -EINVAL;
-	}
-
-	onic_req = (struct onic_dma_request *)req->uld_data;
-	if (unlikely(!onic_req)) {
-		pr_err("%s: onic_req is NULL\n", __func__);
-		return -EINVAL;
-	}
-
-	netdev = onic_req->netdev;
-	if (unlikely(!netdev)) {
-		pr_err("%s: netdev is NULL\n", __func__);
-		return -EINVAL;
-	}
-
-	xpriv = netdev_priv(netdev);
-	if (unlikely(!xpriv)) {
-		pr_err("%s: xpriv is NULL\n", __func__);
-		return -EINVAL;
-	}
-
-	skb = onic_req->skb;
-	if (unlikely(!skb)) {
-		netdev_err(netdev, "%s: skb is NULL\n", __func__);
-		return -EINVAL;
-	}
-
-	nb_frags = skb_shinfo(skb)->nr_frags;
-	qdma_sgl = req->sgl;
-	dma_unmap_single(netdev->dev.parent, qdma_sgl->dma_addr,
-			 skb_headlen(skb), DMA_TO_DEVICE);
-
-	netdev_dbg(netdev,
-		   "%s: skb->len = %d skb_headlen(skb) = %d, dma_addr = %llx nb_frags:%d\n",
-		   __func__, skb->len, skb_headlen(skb), qdma_sgl->dma_addr,
-		   nb_frags);
-
-	qdma_sgl = qdma_sgl->next;
-	while (qdma_sgl && (frag_index < nb_frags)) {
-		frag = &skb_shinfo(skb)->frags[frag_index];
-		qdma_sgl->len = skb_frag_size(frag);
-		dma_unmap_single(netdev->dev.parent, qdma_sgl->dma_addr,
-				 qdma_sgl->len, DMA_TO_DEVICE);
-		qdma_sgl = qdma_sgl->next;
-		frag_index++;
-	}
-
-	dev_consume_skb_irq(skb);
-	kmem_cache_free(xpriv->dma_req, onic_req);
-
-	return 0;
+  u16 nb_frags = 0, frag_index = 0;
+  struct qdma_sw_sg *qdma_sgl;
+  struct onic_dma_request *onic_req;
+  struct net_device *netdev;
+  struct sk_buff *skb;
+  struct onic_priv *xpriv;
+  skb_frag_t *frag;
+
+  if (unlikely(!req)) {
+    pr_err("%s: req is NULL\n", __func__);
+    return -EINVAL;
+  }
+
+  onic_req = (struct onic_dma_request *)req->uld_data;
+  if (unlikely(!onic_req)) {
+    pr_err("%s: onic_req is NULL\n", __func__);
+    return -EINVAL;
+  }
+
+  netdev = onic_req->netdev;
+  if (unlikely(!netdev)) {
+    pr_err("%s: netdev is NULL\n", __func__);
+    return -EINVAL;
+  }
+
+  xpriv = netdev_priv(netdev);
+  if (unlikely(!xpriv)) {
+    pr_err("%s: xpriv is NULL\n", __func__);
+    return -EINVAL;
+  }
+
+  skb = onic_req->skb;
+  if (unlikely(!skb)) {
+    netdev_err(netdev, "%s: skb is NULL\n", __func__);
+    return -EINVAL;
+  }
+
+  nb_frags = skb_shinfo(skb)->nr_frags;
+  qdma_sgl = req->sgl;
+  dma_unmap_single(netdev->dev.parent, qdma_sgl->dma_addr,
+       skb_headlen(skb), DMA_TO_DEVICE);
+
+  netdev_dbg(netdev,
+       "%s: skb->len = %d skb_headlen(skb) = %d, dma_addr = %llx nb_frags:%d\n",
+       __func__, skb->len, skb_headlen(skb), qdma_sgl->dma_addr,
+       nb_frags);
+
+  qdma_sgl = qdma_sgl->next;
+  while (qdma_sgl && (frag_index < nb_frags)) {
+    frag = &skb_shinfo(skb)->frags[frag_index];
+    qdma_sgl->len = skb_frag_size(frag);
+    dma_unmap_single(netdev->dev.parent, qdma_sgl->dma_addr,
+         qdma_sgl->len, DMA_TO_DEVICE);
+    qdma_sgl = qdma_sgl->next;
+    frag_index++;
+  }
+
+  dev_consume_skb_irq(skb);
+  kmem_cache_free(xpriv->dma_req, onic_req);
+
+  return 0;
 }
 
 /* This function is called by QDMA core when one or multiple packet
@@ -683,250 +756,250 @@ static int onic_unmap_free_pkt_data(struct qdma_request *req)
  * This function frees skb associated with the transmitted packets.
  */
 static int onic_tx_done(struct qdma_request *req, unsigned int bytes_done,
-			int err)
+      int err)
 {
-	int ret = 0;
+  int ret = 0;
 
-	ret = onic_unmap_free_pkt_data(req);
-	if (ret != 0)
-		pr_err("%s: onic_unmap_free_pkt_data() failed\n", __func__);
+  ret = onic_unmap_free_pkt_data(req);
+  if (ret != 0)
+    pr_err("%s: onic_unmap_free_pkt_data() failed\n", __func__);
 
-	pr_debug("%s: bytes_done = %d, error = %d\n",
-		 __func__, bytes_done, err);
+  pr_debug("%s: bytes_done = %d, error = %d\n",
+     __func__, bytes_done, err);
 
-	return 0;
+  return 0;
 }
 
 /* This function is called from networking stack in order to send packet */
 static int onic_start_xmit(struct sk_buff *skb, struct net_device *netdev)
 {
-	u16 q_id = 0, nb_frags = 0, frag_index = 0;
-	int ret = 0, count = 0;
-	unsigned long q_handle;
-	struct onic_priv *xpriv;
-	struct onic_dma_request *onic_req;
-	struct qdma_request *qdma_req;
-	struct qdma_sw_sg *qdma_sgl;
-	skb_frag_t *frag;
-
-	xpriv = netdev_priv(netdev);
-	if (unlikely(!xpriv)) {
-		pr_err("%s: xpriv is NULL\n", __func__);
-		return -EINVAL;
-	}
-
-	ret = netif_carrier_ok(netdev);
-	if (unlikely(!ret)) {
-		netdev_err(netdev, "%s: Packet sent when carrier is down\n",
-			   __func__);
-		dev_kfree_skb_any(skb);
-		return -EINVAL;
-	}
-
-	if (unlikely(skb_is_gso(skb))) {
-		netdev_err(netdev, "%s: Received GSO SKB\n", __func__);
-		return -EINVAL;
-	}
-
-	/* minimum Ethernet packet length is 60 */
-	ret = skb_put_padto(skb, ETH_ZLEN);
-	if (unlikely(ret != 0)) {
-		netdev_err(netdev, "%s: skb_put_padto failed with status %d\n", __func__, ret);
-		dev_kfree_skb_any(skb);
-		return -EINVAL;
-	}
-
-	q_id = skb_get_queue_mapping(skb);
-	if (unlikely(q_id >= netdev->real_num_tx_queues)) {
-		netdev_err(netdev, "%s: Invalid queue mapping. q_id = %d\n",
-			   __func__, q_id);
-		dev_kfree_skb_any(skb);
-		return -EINVAL;
-	}
-
-	q_handle = xpriv->base_tx_q_handle + q_id;
-
-	onic_req = kmem_cache_zalloc(xpriv->dma_req, GFP_ATOMIC);
-	if (unlikely(!onic_req)) {
-		netdev_err(netdev, "%s: onic_req allocation failed\n",
-			   __func__);
-		return -ENOMEM;
-	}
-	qdma_req = &onic_req->qdma;
-	qdma_sgl = &onic_req->sgl[0];
-
-	onic_req->skb = skb;
-	onic_req->netdev = netdev;
-
-	qdma_req->sgl = qdma_sgl;
-
-	qdma_sgl->len = skb_headlen(skb);
-	qdma_req->count = qdma_sgl->len;
-
-	qdma_sgl->dma_addr = dma_map_single(netdev->dev.parent, skb->data,
-					    skb_headlen(skb), DMA_TO_DEVICE);
-	ret = dma_mapping_error(netdev->dev.parent, qdma_sgl->dma_addr);
-	if (unlikely(ret)) {
-		netdev_err(netdev, "%s: dma_map_single() failed\n", __func__);
-		ret = -EFAULT;
-		goto free_packet_data;
-	}
-
-	qdma_sgl->next = NULL;
-	qdma_req->sgcnt++;
-	nb_frags = skb_shinfo(skb)->nr_frags;
-	/* DMA mapping for fragments data */
-	for (frag_index = 0; frag_index < nb_frags; frag_index++) {
-		qdma_sgl->next = (qdma_sgl + 1);
-		qdma_sgl = qdma_sgl->next;
-		qdma_sgl->next = NULL;
-
-		frag = &skb_shinfo(skb)->frags[frag_index];
-		qdma_sgl->len = skb_frag_size(frag);
-		qdma_req->count += qdma_sgl->len;
-
-		netdev_dbg(netdev, "%s: frag no = %d, skb_frag_size = %d\n",
-			   __func__, frag_index, qdma_sgl->len);
-
-		qdma_sgl->dma_addr = (unsigned long)skb_frag_dma_map(
-								     netdev->dev.parent, frag, 0, skb_frag_size(frag),
-								     DMA_TO_DEVICE);
-		ret = dma_mapping_error(netdev->dev.parent, qdma_sgl->dma_addr);
-		if (unlikely(ret)) {
-			netdev_err(netdev, "%s: dma_map_single failed\n",
-				   __func__);
-			ret = -EFAULT;
-			goto free_packet_data;
-		}
-		qdma_req->sgcnt++;
-	}
-
-	qdma_req->dma_mapped = 1;
-	qdma_req->check_qstate_disabled = 1;
-	qdma_req->fp_done = onic_tx_done;
-	qdma_req->uld_data = (unsigned long)onic_req;
-
-	count = qdma_queue_packet_write(xpriv->dev_handle, q_handle, qdma_req);
-	if (unlikely(count < 0)) {
-		netdev_err(netdev,
-			   "%s: qdma_queue_packet_write() failed, err = %d\n",
-			   __func__, count);
-		ret = count;
-		goto free_packet_data;
-	}
-
-	xpriv->tx_qstats[q_id].tx_packets++;
-	xpriv->tx_qstats[q_id].tx_bytes += skb->len;
-
-	return NETDEV_TX_OK;
+  u16 q_id = 0, nb_frags = 0, frag_index = 0;
+  int ret = 0, count = 0;
+  unsigned long q_handle;
+  struct onic_priv *xpriv;
+  struct onic_dma_request *onic_req;
+  struct qdma_request *qdma_req;
+  struct qdma_sw_sg *qdma_sgl;
+  skb_frag_t *frag;
+
+  xpriv = netdev_priv(netdev);
+  if (unlikely(!xpriv)) {
+    pr_err("%s: xpriv is NULL\n", __func__);
+    return -EINVAL;
+  }
+
+  ret = netif_carrier_ok(netdev);
+  if (unlikely(!ret)) {
+    netdev_err(netdev, "%s: Packet sent when carrier is down\n",
+         __func__);
+    dev_kfree_skb_any(skb);
+    return -EINVAL;
+  }
+
+  if (unlikely(skb_is_gso(skb))) {
+    netdev_err(netdev, "%s: Received GSO SKB\n", __func__);
+    return -EINVAL;
+  }
+
+  /* minimum Ethernet packet length is 60 */
+  ret = skb_put_padto(skb, ETH_ZLEN);
+  if (unlikely(ret != 0)) {
+    netdev_err(netdev, "%s: skb_put_padto failed with status %d\n", __func__, ret);
+    dev_kfree_skb_any(skb);
+    return -EINVAL;
+  }
+
+  q_id = skb_get_queue_mapping(skb);
+
+  if (unlikely(q_id >= netdev->real_num_tx_queues)) {
+    netdev_err(netdev, "%s: Invalid queue mapping. q_id = %d\n",
+         __func__, q_id);
+    dev_kfree_skb_any(skb);
+    return -EINVAL;
+  }
+
+  if(q_id >= QDMA_NET_QUEUE) return 0; // mm queue does not need to do this
+
+  q_handle = xpriv->base_tx_q_handle + q_id;
+
+  onic_req = kmem_cache_zalloc(xpriv->dma_req, GFP_ATOMIC);
+  if (unlikely(!onic_req)) {
+    netdev_err(netdev, "%s: onic_req allocation failed\n",
+         __func__);
+    return -ENOMEM;
+  }
+  qdma_req = &onic_req->qdma;
+  qdma_sgl = &onic_req->sgl[0];
+
+  onic_req->skb = skb;
+  onic_req->netdev = netdev;
+
+  qdma_req->sgl = qdma_sgl;
+
+  qdma_sgl->len = skb_headlen(skb);
+  qdma_req->count = qdma_sgl->len;
+
+  qdma_sgl->dma_addr = dma_map_single(netdev->dev.parent, skb->data,
+              skb_headlen(skb), DMA_TO_DEVICE);
+  ret = dma_mapping_error(netdev->dev.parent, qdma_sgl->dma_addr);
+  if (unlikely(ret)) {
+    netdev_err(netdev, "%s: dma_map_single() failed\n", __func__);
+    ret = -EFAULT;
+    goto free_packet_data;
+  }
+
+  qdma_sgl->next = NULL;
+  qdma_req->sgcnt++;
+  nb_frags = skb_shinfo(skb)->nr_frags;
+  /* DMA mapping for fragments data */
+  for (frag_index = 0; frag_index < nb_frags; frag_index++) {
+    qdma_sgl->next = (qdma_sgl + 1);
+    qdma_sgl = qdma_sgl->next;
+    qdma_sgl->next = NULL;
+
+    frag = &skb_shinfo(skb)->frags[frag_index];
+    qdma_sgl->len = skb_frag_size(frag);
+    qdma_req->count += qdma_sgl->len;
+
+    netdev_dbg(netdev, "%s: frag no = %d, skb_frag_size = %d\n",
+         __func__, frag_index, qdma_sgl->len);
+
+    qdma_sgl->dma_addr = (unsigned long)skb_frag_dma_map(
+                     netdev->dev.parent, frag, 0, skb_frag_size(frag),
+                     DMA_TO_DEVICE);
+    ret = dma_mapping_error(netdev->dev.parent, qdma_sgl->dma_addr);
+    if (unlikely(ret)) {
+      netdev_err(netdev, "%s: dma_map_single failed\n",
+           __func__);
+      ret = -EFAULT;
+      goto free_packet_data;
+    }
+    qdma_req->sgcnt++;
+  }
+
+  qdma_req->dma_mapped = 1;
+  qdma_req->check_qstate_disabled = 1;
+  qdma_req->fp_done = onic_tx_done;
+  qdma_req->uld_data = (unsigned long)onic_req;
+
+  count = qdma_queue_packet_write(xpriv->dev_handle, q_handle, qdma_req);
+  if (unlikely(count < 0)) {
+    netdev_err(netdev,
+         "%s: qdma_queue_packet_write() failed, err = %d\n",
+         __func__, count);
+    ret = count;
+    goto free_packet_data;
+  }
+
+  xpriv->tx_qstats[q_id].tx_packets++;
+  xpriv->tx_qstats[q_id].tx_bytes += skb->len;
+
+  return NETDEV_TX_OK;
 
 free_packet_data:
-	if (onic_unmap_free_pkt_data(qdma_req) != 0) {
-		netdev_err(netdev, "%s: onic_unmap_free_pkt_data() failed\n",
-			   __func__);
-		kmem_cache_free(xpriv->dma_req, onic_req);
-	}
-	xpriv->tx_qstats[q_id].tx_dropped++;
-	return ret;
+  if (onic_unmap_free_pkt_data(qdma_req) != 0) {
+    netdev_err(netdev, "%s: onic_unmap_free_pkt_data() failed\n",
+         __func__);
+    kmem_cache_free(xpriv->dma_req, onic_req);
+  }
+  xpriv->tx_qstats[q_id].tx_dropped++;
+  return ret;
 }
 
 static int onic_set_mac_address(struct net_device *dev, void *addr)
 {
-	struct sockaddr *saddr = addr;
-	u8 *dev_addr = saddr->sa_data;
-	if (!is_valid_ether_addr(saddr->sa_data))
-		return -EADDRNOTAVAIL;
-
-	netdev_info(dev, "Set MAC address to %x:%x:%x:%x:%x:%x",
-		    dev_addr[0], dev_addr[1], dev_addr[2],
-		    dev_addr[3], dev_addr[4], dev_addr[5]);
-	memcpy(dev->dev_addr, dev_addr, dev->addr_len);
-	return 0;
+  struct sockaddr *saddr = addr;
+  u8 *dev_addr = saddr->sa_data;
+  if (!is_valid_ether_addr(saddr->sa_data))
+    return -EADDRNOTAVAIL;
+
+  netdev_info(dev, "Set MAC address to %x:%x:%x:%x:%x:%x",
+        dev_addr[0], dev_addr[1], dev_addr[2],
+        dev_addr[3], dev_addr[4], dev_addr[5]);
+#if LINUX_VERSION_CODE < KERNEL_VERSION(5, 18, 0)
+  memcpy(dev->dev_addr, dev_addr, dev->addr_len);
+#else // LINUX_VERSION_CODE >= KERNEL_VERSION(5, 18, 0)
+  eth_hw_addr_set(dev, dev_addr);
+#endif
+  return 0;
 };
 
 static int onic_do_ioctl(struct net_device *netdev, struct ifreq *ifr, int cmd)
 {
-	return 0;
+  return 0;
 }
 
 static int onic_change_mtu(struct net_device *netdev, int mtu)
 {
-	netdev_info(netdev, "Requestd MTU = %d", mtu);
-	return 0;
+  netdev_info(netdev, "Requestd MTU = %d", mtu);
+  return 0;
 }
 
 static void onic_get_stats64(struct net_device *netdev,
-			     struct rtnl_link_stats64 *stats)
+           struct rtnl_link_stats64 *stats)
 {
-	u32 q_num = 0;
-	struct onic_priv *xpriv;
-
-	if (!netdev) {
-		pr_err("%s: netdev is NULL\n", __func__);
-		return;
-	}
-
-	xpriv = netdev_priv(netdev);
-	if (!xpriv) {
-		pr_err("%s: xpriv is NULL\n", __func__);
-		return;
-	}
-
-	if ((xpriv->tx_qstats != NULL) && (xpriv->rx_qstats != NULL)) {
-		for (q_num = 0; q_num < netdev->real_num_tx_queues; q_num++) {
-			stats->tx_bytes += xpriv->tx_qstats[q_num].tx_bytes;
-			stats->tx_packets += xpriv->tx_qstats[q_num].tx_packets;
-		}
-
-		for (q_num = 0; q_num < netdev->real_num_rx_queues; q_num++) {
-			stats->rx_bytes += xpriv->rx_qstats[q_num].rx_bytes;
-			stats->rx_packets += xpriv->rx_qstats[q_num].rx_packets;
-		}
-	}
+  u32 q_num = 0;
+  struct onic_priv *xpriv;
+
+  if (!netdev) {
+    pr_err("%s: netdev is NULL\n", __func__);
+    return;
+  }
+
+  xpriv = netdev_priv(netdev);
+  if (!xpriv) {
+    pr_err("%s: xpriv is NULL\n", __func__);
+    return;
+  }
+
+  if ((xpriv->tx_qstats != NULL) && (xpriv->rx_qstats != NULL)) {
+    for (q_num = 0; q_num < netdev->real_num_tx_queues; q_num++) {
+      stats->tx_bytes += xpriv->tx_qstats[q_num].tx_bytes;
+      stats->tx_packets += xpriv->tx_qstats[q_num].tx_packets;
+    }
+
+    for (q_num = 0; q_num < netdev->real_num_rx_queues; q_num++) {
+      stats->rx_bytes += xpriv->rx_qstats[q_num].rx_bytes;
+      stats->rx_packets += xpriv->rx_qstats[q_num].rx_packets;
+    }
+  }
 }
 
-/* Network Device Operations */
-static const struct net_device_ops onic_netdev_ops = {
-	.ndo_open = onic_open,
-	.ndo_stop = onic_stop,
-	.ndo_start_xmit = onic_start_xmit,
-	.ndo_set_mac_address = onic_set_mac_address,
-	.ndo_do_ioctl = onic_do_ioctl,
-	.ndo_change_mtu = onic_change_mtu,
-	.ndo_get_stats64 = onic_get_stats64
-};
-
 static int onic_set_num_queue(struct onic_priv *xpriv)
 {
-	unsigned short int nb_queues;
-	int num_msix;
+  unsigned short int nb_queues;
+  int num_msix;
+
+  num_msix = pci_msix_vec_count(xpriv->pcidev);
 
-	num_msix = pci_msix_vec_count(xpriv->pcidev);
-	if (num_msix <= 0) {
-		pr_err("%s:No MSIX cpability %d\n", __func__, num_msix);
-		return num_msix;
-	}
+  if (num_msix <= 0) {
+    pr_err("%s:No MSIX cpability %d\n", __func__, num_msix);
+    return num_msix;
+  }
 
-	nb_queues = num_msix;
-	nb_queues -= xpriv->pinfo->pci_msix_user_cnt;
-	if (xpriv->pinfo->pci_master_pf)
-		nb_queues--;
+  nb_queues = num_msix;
+  nb_queues -= xpriv->pinfo->pci_msix_user_cnt;
 
-	xpriv->num_msix = num_msix;
-	xpriv->nb_queues = nb_queues;
+  pr_warn("%s: num_msix %d, nb_queues %d, pci_msix_user_cnt %d\n", __func__, num_msix, nb_queues, xpriv->pinfo->pci_msix_user_cnt);
 
-	return 0;
+  if (xpriv->pinfo->pci_master_pf)
+    nb_queues--;
+
+  xpriv->num_msix = num_msix;
+  xpriv->nb_queues = nb_queues;
+
+  return 0;
 }
 
 static int onic_arr_find(unsigned int *arr, int n, int element)
 {
-	int i = 0;
+  int i = 0;
 
-	for (i = 0; i < n; i++) {
-		if (*(arr + i) == element)
-			return i;
-	}
-	return -1;
+  for (i = 0; i < n; i++) {
+    if (*(arr + i) == element)
+      return i;
+  }
+  return -1;
 }
 
 /* This function gets global CSR and sets the default indexes of the
@@ -935,358 +1008,446 @@ static int onic_arr_find(unsigned int *arr, int n, int element)
  */
 static int onic_qdma_csr_index_setup(struct onic_priv *xpriv)
 {
-	int ret = 0, index = 0;
-	struct global_csr_conf csr_conf;
-
-	ret = qdma_global_csr_get(xpriv->dev_handle, 0,
-				  QDMA_GLOBAL_CSR_ARRAY_SZ, &csr_conf);
-	if (ret != 0) {
-		dev_err(&xpriv->pcidev->dev, 
-			"%s: qdma_global_csr_get() failed with status %d\n",
-			__func__, ret);
-		return -EINVAL;
-	}
-
-	index = onic_arr_find(csr_conf.ring_sz, QDMA_GLOBAL_CSR_ARRAY_SZ,
-			      xpriv->pinfo->ring_sz);
-	if (index < 0) {
-		dev_err(&xpriv->pcidev->dev, 
-			"%s: Expected ring size %d not found\n", __func__, ret);
-		return index;
-	}
-	xpriv->tx_desc_rng_sz_idx = index;
-	xpriv->rx_desc_rng_sz_idx = index;
-	xpriv->cmpl_rng_sz_idx = index;
-
-	index = onic_arr_find(csr_conf.c2h_timer_cnt, QDMA_GLOBAL_CSR_ARRAY_SZ,
-			      xpriv->pinfo->c2h_tmr_cnt);
-	if (index < 0) {
-		dev_err(&xpriv->pcidev->dev,
-			"%s: Expected default C2H Timer count %d not found\n",
-			__func__, xpriv->pinfo->c2h_tmr_cnt);
-		return index;
-	}
-	xpriv->rx_timer_idx = index;
-
-	index = onic_arr_find(csr_conf.c2h_cnt_th, QDMA_GLOBAL_CSR_ARRAY_SZ,
-			      xpriv->pinfo->c2h_cnt_thr);
-	if (index < 0) {
-		dev_err(&xpriv->pcidev->dev,
-			"%s: Expected default C2H count threshold count %d not found\n",
-			__func__, xpriv->pinfo->c2h_cnt_thr);
-		return index;
-	}
-	xpriv->rx_cnt_th_idx = index;
-
-	index = onic_arr_find(csr_conf.c2h_buf_sz, QDMA_GLOBAL_CSR_ARRAY_SZ,
-			      xpriv->pinfo->c2h_buf_sz);
-	if (index < 0) {
-		dev_err(&xpriv->pcidev->dev,
-			"%s: Expected default C2H Buffer size %d not found",
-			__func__, xpriv->pinfo->c2h_buf_sz);
-		return index;
-	}
-	xpriv->rx_buf_sz_idx = index;
-	return 0;
+  int ret = 0, index = 0;
+  struct global_csr_conf csr_conf;
+
+  ret = qdma_global_csr_get(xpriv->dev_handle, 0,
+          QDMA_GLOBAL_CSR_ARRAY_SZ, &csr_conf);
+  if (ret != 0) {
+    dev_err(&xpriv->pcidev->dev,
+      "%s: qdma_global_csr_get() failed with status %d\n",
+      __func__, ret);
+    return -EINVAL;
+  }
+
+  index = onic_arr_find(csr_conf.ring_sz, QDMA_GLOBAL_CSR_ARRAY_SZ,
+            xpriv->pinfo->ring_sz);
+  if (index < 0) {
+    dev_err(&xpriv->pcidev->dev,
+      "%s: Expected ring size %d not found\n", __func__, ret);
+    return index;
+  }
+  xpriv->tx_desc_rng_sz_idx = index;
+  xpriv->rx_desc_rng_sz_idx = index;
+  xpriv->cmpl_rng_sz_idx = index;
+
+  index = onic_arr_find(csr_conf.c2h_timer_cnt, QDMA_GLOBAL_CSR_ARRAY_SZ,
+            xpriv->pinfo->c2h_tmr_cnt);
+  if (index < 0) {
+    dev_err(&xpriv->pcidev->dev,
+      "%s: Expected default C2H Timer count %d not found\n",
+      __func__, xpriv->pinfo->c2h_tmr_cnt);
+    return index;
+  }
+  xpriv->rx_timer_idx = index;
+
+  index = onic_arr_find(csr_conf.c2h_cnt_th, QDMA_GLOBAL_CSR_ARRAY_SZ,
+            xpriv->pinfo->c2h_cnt_thr);
+  if (index < 0) {
+    dev_err(&xpriv->pcidev->dev,
+      "%s: Expected default C2H count threshold count %d not found\n",
+      __func__, xpriv->pinfo->c2h_cnt_thr);
+    return index;
+  }
+  xpriv->rx_cnt_th_idx = index;
+
+  index = onic_arr_find(csr_conf.c2h_buf_sz, QDMA_GLOBAL_CSR_ARRAY_SZ,
+            xpriv->pinfo->c2h_buf_sz);
+  if (index < 0) {
+    dev_err(&xpriv->pcidev->dev,
+      "%s: Expected default C2H Buffer size %d not found",
+      __func__, xpriv->pinfo->c2h_buf_sz);
+    return index;
+  }
+  xpriv->rx_buf_sz_idx = index;
+  return 0;
 }
 
 /* Configure QDMA Device, Global CSR Registers */
 static int onic_qdma_setup(struct onic_priv *xpriv)
 {
-	int ret;
-
-	memset(&xpriv->qdma_dev_conf, 0, sizeof(struct qdma_dev_conf));
-
-	xpriv->qdma_dev_conf.bar_num_config = xpriv->pinfo->qdma_bar;
-	xpriv->qdma_dev_conf.msix_qvec_max = xpriv->num_msix;
-	xpriv->qdma_dev_conf.data_msix_qvec_max = xpriv->nb_queues;
-	xpriv->qdma_dev_conf.user_msix_qvec_max = xpriv->pinfo->pci_msix_user_cnt;
-	xpriv->qdma_dev_conf.master_pf = xpriv->pinfo->pci_master_pf;
-	if (!xpriv->pinfo->poll_mode)
-		xpriv->qdma_dev_conf.intr_moderation =
-			xpriv->pinfo->intr_mod_en;
-	xpriv->qdma_dev_conf.qsets_max = xpriv->pinfo->queue_max;
-	xpriv->qdma_dev_conf.qsets_base = xpriv->pinfo->queue_base;
-	xpriv->qdma_dev_conf.pdev = xpriv->pcidev;
-	if (xpriv->pinfo->poll_mode)
-		xpriv->qdma_dev_conf.qdma_drv_mode = POLL_MODE;
-	else
-		xpriv->qdma_dev_conf.qdma_drv_mode = DIRECT_INTR_MODE;
-
-	ret = qdma_device_open(onic_drv_name, &xpriv->qdma_dev_conf, &xpriv->dev_handle);
-	if (ret != 0) {
-		dev_err(&xpriv->pcidev->dev, 
-			"%s: qdma_device_open() failed: Error Code: %d\n",
-			__func__, ret);
-		return -EINVAL;
-	}
-
-	ret = onic_qdma_csr_index_setup(xpriv);
-	if (ret != 0) {
-		dev_err(&xpriv->pcidev->dev,
-			"%s: onic_qdma_csr_index_setup() failed width status %d\n",
-			__func__, ret);
-		ret = -EINVAL;
-		goto close_qdma;
-	}
-
-	return 0;
+  int ret;
+
+  memset(&xpriv->qdma_dev_conf, 0, sizeof(struct qdma_dev_conf));
+
+  xpriv->qdma_dev_conf.bar_num_config = xpriv->pinfo->qdma_bar;
+  xpriv->qdma_dev_conf.msix_qvec_max = xpriv->num_msix;
+  xpriv->qdma_dev_conf.data_msix_qvec_max = xpriv->nb_queues;
+  xpriv->qdma_dev_conf.user_msix_qvec_max = xpriv->pinfo->pci_msix_user_cnt;
+  xpriv->qdma_dev_conf.master_pf = xpriv->pinfo->pci_master_pf;
+  if (!xpriv->pinfo->poll_mode)
+    xpriv->qdma_dev_conf.intr_moderation =
+      xpriv->pinfo->intr_mod_en;
+  xpriv->qdma_dev_conf.qsets_max = xpriv->pinfo->queue_max;
+  xpriv->qdma_dev_conf.qsets_base = xpriv->pinfo->queue_base;
+  xpriv->qdma_dev_conf.pdev = xpriv->pcidev;
+  if (xpriv->pinfo->poll_mode)
+    xpriv->qdma_dev_conf.qdma_drv_mode = POLL_MODE;
+  else
+    xpriv->qdma_dev_conf.qdma_drv_mode = DIRECT_INTR_MODE;
+
+  ret = qdma_device_open(onic_drv_name, &xpriv->qdma_dev_conf, &xpriv->dev_handle);
+  if (ret != 0) {
+    dev_err(&xpriv->pcidev->dev,
+      "%s: qdma_device_open() failed: Error Code: %d\n",
+      __func__, ret);
+    return -EINVAL;
+  }
+
+  ret = onic_qdma_csr_index_setup(xpriv);
+  if (ret != 0) {
+    dev_err(&xpriv->pcidev->dev,
+      "%s: onic_qdma_csr_index_setup() failed width status %d\n",
+      __func__, ret);
+    ret = -EINVAL;
+    goto close_qdma;
+  }
+
+  return 0;
 
 close_qdma:
-	qdma_device_close(xpriv->pcidev, xpriv->dev_handle);
-	return ret;
+  qdma_device_close(xpriv->pcidev, xpriv->dev_handle);
+  return ret;
 }
 
 static bool onic_rx_lane_aligned(struct onic_priv *xpriv, u8 cmac_id)
 {
-	u32 offset = CMAC_OFFSET_STAT_RX_STATUS(cmac_id);
-	u32 val;
+  u32 offset = CMAC_OFFSET_STAT_RX_STATUS(cmac_id);
+  u32 val;
 
-	/* read twice to flush any previously latched value */
-	val = readl(xpriv->bar_base + offset);
-	val = readl(xpriv->bar_base + offset);
-	return (val == 0x3);
+  /* read twice to flush any previously latched value */
+  val = readl(xpriv->bar_base + offset);
+  val = readl(xpriv->bar_base + offset);
+  return (val == 0x3);
 }
 
 static void onic_disable_cmac(struct onic_priv *xpriv)
 {
-	u8 cmac_id = xpriv->pinfo->port_id;
+  u8 cmac_id = xpriv->pinfo->port_id;
 
-	writel(0x0, xpriv->bar_base + CMAC_OFFSET_CONF_TX_1(cmac_id));
-	writel(0x0, xpriv->bar_base + CMAC_OFFSET_CONF_RX_1(cmac_id));
+  writel(0x0, xpriv->bar_base + CMAC_OFFSET_CONF_TX_1(cmac_id));
+  writel(0x0, xpriv->bar_base + CMAC_OFFSET_CONF_RX_1(cmac_id));
+}
+
+static void onic_reset_cmac(struct onic_priv *xpriv) {
+  u8 cmac_id = xpriv->pinfo->port_id;
+
+  if (cmac_id == 0) {
+    writel(0x10, xpriv->bar_base + SYSCFG_OFFSET_SHELL_RESET);
+    while ((readl(xpriv->bar_base + SYSCFG_OFFSET_SHELL_STATUS) & 0x10) != 0x10)
+      mdelay(1);
+  } else {
+    writel(0x100, xpriv->bar_base + SYSCFG_OFFSET_SHELL_RESET);
+    while ((readl(xpriv->bar_base + SYSCFG_OFFSET_SHELL_STATUS) & 0x100) != 0x100)
+      mdelay(1);
+  }
 }
 
 static int onic_enable_cmac(struct onic_priv *xpriv)
 {
-	u8 cmac_id = xpriv->pinfo->port_id;
-
-	if (xpriv->pinfo->rsfec_en) {
-		/* Enable RS-FEC for CMACs with RS-FEC implemented */
-		writel(0x3, xpriv->bar_base + CMAC_OFFSET_RSFEC_CONF_ENABLE(cmac_id));
-		writel(0x7, xpriv->bar_base + CMAC_OFFSET_RSFEC_CONF_IND_CORRECTION(cmac_id));
-	}
-
-	if (cmac_id == 0) {
-		writel(0x10, xpriv->bar_base + SYSCFG_OFFSET_SHELL_RESET);
-		while ((readl(xpriv->bar_base + SYSCFG_OFFSET_SHELL_STATUS) & 0x10) != 0x10)
-			mdelay(1);
-	} else {
-		writel(0x100, xpriv->bar_base + SYSCFG_OFFSET_SHELL_RESET);
-		while ((readl(xpriv->bar_base + SYSCFG_OFFSET_SHELL_STATUS) & 0x100) != 0x100)
-			mdelay(1);
-	}
-
-	writel(0x1, xpriv->bar_base + CMAC_OFFSET_CONF_RX_1(cmac_id));
-	writel(0x10, xpriv->bar_base + CMAC_OFFSET_CONF_TX_1(cmac_id));
-
-	/* wait for lane alignment */
-	if (!onic_rx_lane_aligned(xpriv, cmac_id)) {
-		mdelay(100);
-		if (!onic_rx_lane_aligned(xpriv, cmac_id))
-			goto rx_not_aligned;
-	}
-
-	writel(0x1, xpriv->bar_base + CMAC_OFFSET_CONF_TX_1(cmac_id));
-
-	/* RX flow control */
-	writel(0x00003DFF, xpriv->bar_base + CMAC_OFFSET_CONF_RX_FC_CTRL_1(cmac_id));
-	writel(0x0001C631, xpriv->bar_base + CMAC_OFFSET_CONF_RX_FC_CTRL_2(cmac_id));
-
-	/* TX flow control */
-	writel(0xFFFFFFFF, xpriv->bar_base + CMAC_OFFSET_CONF_TX_FC_QNTA_1(cmac_id));
-	writel(0xFFFFFFFF, xpriv->bar_base + CMAC_OFFSET_CONF_TX_FC_QNTA_2(cmac_id));
-	writel(0xFFFFFFFF, xpriv->bar_base + CMAC_OFFSET_CONF_TX_FC_QNTA_3(cmac_id));
-	writel(0xFFFFFFFF, xpriv->bar_base + CMAC_OFFSET_CONF_TX_FC_QNTA_4(cmac_id));
-	writel(0x0000FFFF, xpriv->bar_base + CMAC_OFFSET_CONF_TX_FC_QNTA_5(cmac_id));
-	writel(0xFFFFFFFF, xpriv->bar_base + CMAC_OFFSET_CONF_TX_FC_RFRH_1(cmac_id));
-	writel(0xFFFFFFFF, xpriv->bar_base + CMAC_OFFSET_CONF_TX_FC_RFRH_2(cmac_id));
-	writel(0xFFFFFFFF, xpriv->bar_base + CMAC_OFFSET_CONF_TX_FC_RFRH_3(cmac_id));
-	writel(0xFFFFFFFF, xpriv->bar_base + CMAC_OFFSET_CONF_TX_FC_RFRH_4(cmac_id));
-	writel(0x0000FFFF, xpriv->bar_base + CMAC_OFFSET_CONF_TX_FC_RFRH_5(cmac_id));
-	writel(0x000001FF, xpriv->bar_base + CMAC_OFFSET_CONF_TX_FC_CTRL_1(cmac_id));
-
-	return 0;
+  int timeout_cnt = 0;
+  u8 cmac_id = xpriv->pinfo->port_id;
+
+  onic_reset_cmac(xpriv);
+
+  if (xpriv->pinfo->rsfec_en) {
+    /* Enable RS-FEC for CMACs with RS-FEC implemented */
+    writel(0x3, xpriv->bar_base + CMAC_OFFSET_RSFEC_CONF_ENABLE(cmac_id));
+    writel(0x7, xpriv->bar_base + CMAC_OFFSET_RSFEC_CONF_IND_CORRECTION(cmac_id));
+  }
+
+  writel(0x1, xpriv->bar_base + CMAC_OFFSET_CONF_RX_1(cmac_id));
+  writel(0x10, xpriv->bar_base + CMAC_OFFSET_CONF_TX_1(cmac_id));
+
+  /* wait for lane alignment */
+  while(!onic_rx_lane_aligned(xpriv, cmac_id)) {
+    mdelay(50);
+    timeout_cnt++;
+
+    if (timeout_cnt == CMAC_RX_LANE_ALIGNMENT_RESET_CNT) {
+      onic_reset_cmac(xpriv);
+      writel(0x1, xpriv->bar_base + CMAC_OFFSET_CONF_RX_1(cmac_id));
+      writel(0x10, xpriv->bar_base + CMAC_OFFSET_CONF_TX_1(cmac_id));
+    }
+
+    if (timeout_cnt > CMAC_RX_LANE_ALIGNMENT_TIMEOUT_CNT) {
+      goto rx_not_aligned;
+    }
+  }
+
+  writel(0x1, xpriv->bar_base + CMAC_OFFSET_CONF_TX_1(cmac_id));
+
+  /* RX flow control */
+  writel(0x00003DFF, xpriv->bar_base + CMAC_OFFSET_CONF_RX_FC_CTRL_1(cmac_id));
+  writel(0x0001C631, xpriv->bar_base + CMAC_OFFSET_CONF_RX_FC_CTRL_2(cmac_id));
+
+  /* TX flow control */
+  writel(0xFFFFFFFF, xpriv->bar_base + CMAC_OFFSET_CONF_TX_FC_QNTA_1(cmac_id));
+  writel(0xFFFFFFFF, xpriv->bar_base + CMAC_OFFSET_CONF_TX_FC_QNTA_2(cmac_id));
+  writel(0xFFFFFFFF, xpriv->bar_base + CMAC_OFFSET_CONF_TX_FC_QNTA_3(cmac_id));
+  writel(0xFFFFFFFF, xpriv->bar_base + CMAC_OFFSET_CONF_TX_FC_QNTA_4(cmac_id));
+  writel(0x0000FFFF, xpriv->bar_base + CMAC_OFFSET_CONF_TX_FC_QNTA_5(cmac_id));
+  writel(0xFFFFFFFF, xpriv->bar_base + CMAC_OFFSET_CONF_TX_FC_RFRH_1(cmac_id));
+  writel(0xFFFFFFFF, xpriv->bar_base + CMAC_OFFSET_CONF_TX_FC_RFRH_2(cmac_id));
+  writel(0xFFFFFFFF, xpriv->bar_base + CMAC_OFFSET_CONF_TX_FC_RFRH_3(cmac_id));
+  writel(0xFFFFFFFF, xpriv->bar_base + CMAC_OFFSET_CONF_TX_FC_RFRH_4(cmac_id));
+  writel(0x0000FFFF, xpriv->bar_base + CMAC_OFFSET_CONF_TX_FC_RFRH_5(cmac_id));
+  writel(0x000001FF, xpriv->bar_base + CMAC_OFFSET_CONF_TX_FC_CTRL_1(cmac_id));
+
+  return 0;
 
 rx_not_aligned:
-	onic_disable_cmac(xpriv);
-	return -EBUSY;
+  pr_err("[ERROR] %s, rx_not_aligned\n", __func__);
+  onic_disable_cmac(xpriv);
+  return -EBUSY;
 }
 
 static void onic_init_reta(struct onic_priv *xpriv)
 {
-	u32 val;
-	int i;
-
-	/* inform shell about the function map */
-	val = (FIELD_SET(QDMA_FUNC_QCONF_QBASE_MASK, xpriv->pinfo->queue_base) |
-	       FIELD_SET(QDMA_FUNC_QCONF_NUMQ_MASK,
-			 xpriv->netdev->real_num_rx_queues));
-	writel(val, xpriv->bar_base +
-	       QDMA_FUNC_OFFSET_QCONF(xpriv->pinfo->port_id)); 
-
-	/* initialize indirection table */
-	for (i = 0; i < 128; i++) {
-		u32 val = (i % xpriv->netdev->real_num_rx_queues) & 0x0000FFFF;
-		u32 offset = QDMA_FUNC_OFFSET_INDIR_TABLE(xpriv->pinfo->port_id, i);
-		writel(val, xpriv->bar_base + offset);
-	}
+  u32 val;
+  int i;
+
+  /* inform shell about the function map */
+  val = (FIELD_SET(QDMA_FUNC_QCONF_QBASE_MASK, xpriv->pinfo->queue_base) |
+         FIELD_SET(QDMA_FUNC_QCONF_NUMQ_MASK,
+       xpriv->netdev->real_num_rx_queues));
+  writel(val, xpriv->bar_base +
+         QDMA_FUNC_OFFSET_QCONF(xpriv->pinfo->port_id));
+
+  /* initialize indirection table */
+  for (i = 0; i < 128; i++) {
+    u32 val = (i % xpriv->netdev->real_num_rx_queues) & 0x0000FFFF;
+    u32 offset = QDMA_FUNC_OFFSET_INDIR_TABLE(xpriv->pinfo->port_id, i);
+    writel(val, xpriv->bar_base + offset);
+  }
 
 }
 
-static int onic_get_pinfo(struct pci_dev *pdev, struct onic_platform_info
-			  **pinfo_ref)
+static int onic_config_platform(struct onic_platform_info **pinfo_ref, u8 qdma_bar,
+                                u8 qdma_user_bar, u16 queue_base, u16 queue_max,
+                                u16 mm_queues, int ring_sz, int c2h_tmr_cnt,
+                                int c2h_cnt_thr, int c2h_buf_sz, u8 port_id,
+                                u8 pci_msix_user_cnt, bool is_poll_mode, bool rsfec_en)
 {
-	int ret;
-	struct onic_platform_info *pinfo;
-	char file_name[50] = {0};
-
-	pinfo = kzalloc(sizeof(struct onic_platform_info), GFP_KERNEL);
-	if (!pinfo)
-		return -ENOMEM;
-
-	sprintf(file_name, "onic_%4x.json", pdev->device);
-	ret = onic_get_platform_info(file_name, pinfo);
-
-	if (ret) {
-		pr_err("%s: onic_get_platform_info failed\n", __func__);
-		kfree(pinfo);
-		return ret;
-	}
-
-	*pinfo_ref = pinfo;
-
-	return 0;
+  struct onic_platform_info *pinfo;
+
+  pinfo = kzalloc(sizeof(struct onic_platform_info), GFP_KERNEL);
+  if (!pinfo)
+    return -ENOMEM;
+
+  pinfo->qdma_bar = qdma_bar;
+  pinfo->user_bar = qdma_user_bar;
+  pinfo->queue_base = queue_base;
+  pinfo->queue_max = queue_max;
+  pinfo->port_id = port_id;
+  pinfo->mm_queues = mm_queues;
+  //pinfo->used_queues = QDMA_NET_QUEUE + mm_queues;
+  pinfo->used_queues = QDMA_NET_QUEUE;
+  pinfo->active_tx_queues = 0;
+  pinfo->active_rx_queues = 0;
+  pinfo->ring_sz = ring_sz;
+  pinfo->c2h_tmr_cnt = c2h_tmr_cnt;
+  pinfo->c2h_cnt_thr = c2h_cnt_thr;
+  pinfo->c2h_buf_sz  = c2h_buf_sz;
+  pinfo->rsfec_en = rsfec_en;
+  pinfo->pci_msix_user_cnt = pci_msix_user_cnt;
+  pinfo->poll_mode = is_poll_mode;
+  pinfo->intr_mod_en = is_poll_mode ? false : true;
+
+  *pinfo_ref = pinfo;
+  return 0;
 }
 
+/* Network Device Operations */
+static const struct net_device_ops onic_netdev_ops = {
+  .ndo_open = onic_open,
+  .ndo_stop = onic_stop,
+  .ndo_start_xmit = onic_start_xmit,
+  .ndo_set_mac_address = onic_set_mac_address,
+  .ndo_do_ioctl = onic_do_ioctl,
+  .ndo_change_mtu = onic_change_mtu,
+  .ndo_get_stats64 = onic_get_stats64
+};
+
 extern void onic_set_ethtool_ops(struct net_device *netdev);
 
 /* This is probe function which is called when Linux kernel detects PCIe device
  * with Vendor ID and Device ID listed in the in onic_pci_ids table.
  * From this function netdevice and device initialization are done
  */
-static int onic_pci_probe(struct pci_dev *pdev, 
-			  const struct pci_device_id *pci_dev_id)
+static int onic_pci_probe(struct pci_dev *pdev,
+        const struct pci_device_id *pci_dev_id)
 {
-	struct onic_platform_info *pinfo = NULL;
-	struct net_device *netdev;
-	struct onic_priv *xpriv;
-	struct sockaddr saddr;
-	char dev_name[IFNAMSIZ];
-	int ret;
-	u64 bar_start;
-	u64 bar_len;
-
-	ret = onic_get_pinfo(pdev, &pinfo);
-	if (ret) {
-		pr_err("%s: onic_get_pinfo() failed with status %d\n", __func__,
-		       ret);
-		return ret;
-	}
-
-	netdev = alloc_etherdev_mq(sizeof(struct onic_priv),
-				   pinfo->queue_max);
-	if (!netdev) {
-		dev_err(&pdev->dev, "%s: alloc_etherdev_mq() failed\n", __func__);
-		return -ENODEV;
-	}
-
-	SET_NETDEV_DEV(netdev, &pdev->dev);
-	pci_set_drvdata(pdev, netdev);
-	netdev->netdev_ops = &onic_netdev_ops;
-	onic_set_ethtool_ops(netdev);
-
-	snprintf(dev_name, IFNAMSIZ, "onic%ds%df%d",
-		 pdev->bus->number,
-		 PCI_SLOT(pdev->devfn),
-		 PCI_FUNC(pdev->devfn));
-	strlcpy(netdev->name, dev_name, sizeof(netdev->name));
-
-	/* Initialize driver private data */
-	xpriv = netdev_priv(netdev);
-	memset(xpriv, 0, sizeof(struct onic_priv));
-	xpriv->netdev = netdev;
-	xpriv->pcidev = pdev;
-	xpriv->pinfo = pinfo;
-
-	memset(&saddr, 0, sizeof(struct sockaddr));
-	memcpy(saddr.sa_data, pinfo->mac_addr, 6);
-	onic_set_mac_address(netdev, (void *)&saddr);
-
-	if (pinfo->pci_master_pf) {
-		dev_info(&pdev->dev, "device is master PF");
-	}
-
-	ret = onic_set_num_queue(xpriv);
-	if (ret) {
-		goto exit;
-	}
-
-	if (xpriv->pinfo->used_queues > 0 ) {
-		netif_set_real_num_tx_queues(xpriv->netdev,
-					     xpriv->pinfo->used_queues);
-		netif_set_real_num_rx_queues(xpriv->netdev,
-					     xpriv->pinfo->used_queues);
-	} else {
-		netif_set_real_num_tx_queues(xpriv->netdev, xpriv->nb_queues);
-		netif_set_real_num_rx_queues(xpriv->netdev, xpriv->nb_queues);
-	}
-
-	xpriv->dma_req = KMEM_CACHE(onic_dma_request, 0);
-	if (!xpriv->dma_req) {
-		dev_err(&pdev->dev, "%s: Cache alloc failed", __func__);
-		ret = -ENOMEM;
-		goto exit;
-	}
-
-	ret = onic_qdma_setup(xpriv);
-	if (ret != 0) {
-		dev_err(&pdev->dev, "%s: onic_qdma_setup() failed with status %d\n",
-			__func__, ret);
-		goto destroy_kmem_cache;
-	}
-
-	/* Map the User BAR */
-	bar_start = pci_resource_start(pdev, pinfo->user_bar);
-	bar_len = pci_resource_len(pdev, pinfo->user_bar);
-	xpriv->bar_base = ioremap(bar_start, bar_len);
-	if (!xpriv->bar_base) {
-		dev_err(&pdev->dev, "%s: ioremap() failed for BAR%d\n", 
-			__func__, pinfo->user_bar);
-		ret = -EIO;
-		goto close_qdma_device;
-	}
-
-	ret = onic_enable_cmac(xpriv);
-	if (ret != 0) {
-		dev_err(&pdev->dev, "%s: onic_enable_cmac() failed with status %d\n", __func__, ret);
-		goto iounmap_bar;
-	}
-
-	onic_init_reta(xpriv);
-
-	ret = register_netdev(netdev);
-	if (ret != 0) {
-		dev_err(&pdev->dev, "%s: Failed to register network driver\n",
-			__func__);
-		goto disable_cmac;
-	}
-
-	netif_carrier_off(netdev);
-
-	return 0;
+  struct onic_platform_info *pinfo = NULL;
+  struct net_device *netdev;
+  struct onic_priv *xpriv;
+  struct sockaddr saddr;
+  char dev_name[IFNAMSIZ];
+  int ret;
+  u64 bar_start;
+  u64 bar_len;
+  bool is_poll_mode = false;
+  bool en_rsfec = true;
+
+  //ret = onic_get_pinfo(pdev, &pinfo);
+  ret = onic_config_platform(&pinfo, QDMA_BAR, QDMA_USER_BAR, QDMA_QUEUE_BASE, QMDA_TOTAL_QUEUE_ACTIVE,
+                             QDMA_MM_QUEUE, RING_SIZE, C2H_TMR_CNT, C2H_CNT_THR, C2H_BUF_SIZE,
+                             CMAC_PORT_ID, PCI_MSIX_USER_CNT, is_poll_mode, en_rsfec);
+
+  if (ret) {
+    pr_err("%s: onic_config_platform() failed with status %d\n", __func__,
+           ret);
+    return ret;
+  }
+
+  netdev = alloc_etherdev_mq(sizeof(struct onic_priv),
+           pinfo->queue_max);
+  if (!netdev) {
+    dev_err(&pdev->dev, "%s: alloc_etherdev_mq() failed\n", __func__);
+    return -ENODEV;
+  }
+
+  SET_NETDEV_DEV(netdev, &pdev->dev);
+  pci_set_drvdata(pdev, netdev);
+  netdev->netdev_ops = &onic_netdev_ops;
+  onic_set_ethtool_ops(netdev);
+
+  snprintf(dev_name, IFNAMSIZ, "onic%ds%df%d",
+     pdev->bus->number,
+     PCI_SLOT(pdev->devfn),
+     PCI_FUNC(pdev->devfn));
+  strlcpy(netdev->name, dev_name, sizeof(netdev->name));
+
+  /* Initialize driver private data */
+  xpriv = netdev_priv(netdev);
+  memset(xpriv, 0, sizeof(struct onic_priv));
+  xpriv->netdev = netdev;
+  xpriv->pcidev = pdev;
+  xpriv->pinfo = pinfo;
+
+  memset(&saddr, 0, sizeof(struct sockaddr));
+  memcpy(saddr.sa_data, onic_default_dev_addr, 6);
+  get_random_bytes(saddr.sa_data + 3, 3);
+  memcpy(pinfo->mac_addr, saddr.sa_data, 6);
+  onic_set_mac_address(netdev, (void *)&saddr);
+
+  if (PCI_FUNC(pdev->devfn) == 0) {
+    pinfo->pci_master_pf = true;
+    dev_info(&pdev->dev, "device is a master PF");
+  } else {
+    pinfo->pci_master_pf = false;
+    dev_info(&pdev->dev, "device is not a master PF");
+  }
+
+  ret = onic_set_num_queue(xpriv);
+  if (ret) {
+    goto exit;
+  }
+
+  if (xpriv->pinfo->used_queues > 0 ) {
+    netif_set_real_num_tx_queues(xpriv->netdev,
+               xpriv->pinfo->used_queues);
+    netif_set_real_num_rx_queues(xpriv->netdev,
+               xpriv->pinfo->used_queues);
+  } else {
+    netif_set_real_num_tx_queues(xpriv->netdev, xpriv->nb_queues);
+    netif_set_real_num_rx_queues(xpriv->netdev, xpriv->nb_queues);
+  }
+
+  xpriv->dma_req = KMEM_CACHE(onic_dma_request, 0);
+  if (!xpriv->dma_req) {
+    dev_err(&pdev->dev, "%s: Cache alloc failed", __func__);
+    ret = -ENOMEM;
+    goto exit;
+  }
+
+  ret = onic_stats_alloc(xpriv);
+  if (ret != 0) {
+    netdev_err(netdev,
+         "%s: onic_stats_alloc() failed with status %d\n",
+         __func__, ret);
+    goto exit;
+  }
+
+  ret = onic_qdma_setup(xpriv);
+  if (ret != 0) {
+    dev_err(&pdev->dev, "%s: onic_qdma_setup() failed with status %d\n",
+      __func__, ret);
+    goto destroy_kmem_cache;
+  }
+
+  /* Map the User BAR */
+  bar_start = pci_resource_start(pdev, pinfo->user_bar);
+  bar_len = pci_resource_len(pdev, pinfo->user_bar);
+  xpriv->bar_base = ioremap(bar_start, bar_len);
+  if (!xpriv->bar_base) {
+    dev_err(&pdev->dev, "%s: ioremap() failed for BAR%d\n",
+      __func__, pinfo->user_bar);
+    ret = -EIO;
+    goto close_qdma_device;
+  }
+
+  xpriv->onic_cdev_ptr = (struct onic_cdev*) kzalloc(sizeof(struct onic_cdev)+strlen(ONIC_CDEV_CLASS_NAME)+5,
+                   GFP_KERNEL);
+  ret = onic_create_cdev(xpriv->onic_cdev_ptr, xpriv, 0);
+  if(ret < 0) {
+    dev_err(&xpriv->onic_cdev_ptr->qdev->pdev->dev, "Error: onic_init_cdev failed\n");
+    goto destroy_cdev;
+  }
+
+  ret = onic_enable_cmac(xpriv);
+  if (ret != 0) {
+    dev_err(&pdev->dev, "%s: onic_enable_cmac() failed with status %d\n", __func__, ret);
+    goto iounmap_bar;
+  }
+
+  onic_init_reta(xpriv);
+
+  ret = register_netdev(netdev);
+  if (ret != 0) {
+    dev_err(&pdev->dev, "%s: Failed to register network driver\n",
+      __func__);
+    goto disable_cmac;
+  }
+
+  // Set up QDMA queues
+  ret = onic_qdma_rx_queue_setup(xpriv);
+  if (ret != 0) {
+    netdev_err(netdev, "%s: onic_qdmx_rx_queue_setup() failed with status %d\n",
+         __func__, ret);
+    kfree(xpriv->tx_qstats);
+    goto release_rx_queues;
+  }
+
+  ret = onic_qdma_tx_queue_setup(xpriv);
+  if (ret != 0) {
+    netdev_err(netdev, "%s: onic_qdmx_tx_queue_setup() failed with status %d\n",
+         __func__, ret);
+    goto release_queues;
+  }
+
+  netif_carrier_off(netdev);
+
+  return 0;
 
+release_queues:
+  onic_qdma_tx_queue_release(xpriv, xpriv->pinfo->active_tx_queues);
+release_rx_queues:
+  onic_qdma_rx_queue_release(xpriv, xpriv->pinfo->active_rx_queues);
 disable_cmac:
-	onic_disable_cmac(xpriv);
+  onic_disable_cmac(xpriv);
 iounmap_bar:
-	iounmap(xpriv->bar_base);
+  iounmap(xpriv->bar_base);
+destroy_cdev:
+  onic_destroy_cdev(xpriv->onic_cdev_ptr);
 close_qdma_device:
-	qdma_device_close(pdev, xpriv->dev_handle);
+  qdma_device_close(pdev, xpriv->dev_handle);
 destroy_kmem_cache:
-	kmem_cache_destroy(xpriv->dma_req);
+  kmem_cache_destroy(xpriv->dma_req);
 exit:
-	kfree(xpriv->pinfo);
-	free_netdev(netdev);
-	return ret;
+  kfree(xpriv->pinfo);
+  free_netdev(netdev);
+  return ret;
 }
 
 /* This function gets called when PCIe device has been removed from the bus
@@ -1294,38 +1455,44 @@ exit:
  */
 static void onic_pci_remove(struct pci_dev *pdev)
 {
-	struct net_device *netdev = pci_get_drvdata(pdev);
-	struct onic_priv *xpriv;
-
-	if (!netdev) {
-		dev_err(&pdev->dev, "%s: netdev is NULL\n", __func__);
-		return;
-	}
-
-	xpriv = netdev_priv(netdev);
-	if (!xpriv) {
-		dev_err(&pdev->dev, "%s: xpriv is NULL\n", __func__);
-		return;
-	}
-
-	pci_set_drvdata(pdev, NULL);
-	unregister_netdev(netdev);
-
-	onic_disable_cmac(xpriv);
-	if (xpriv->bar_base)
-		iounmap(xpriv->bar_base);
-	qdma_device_close(pdev, xpriv->dev_handle);
-	kmem_cache_destroy(xpriv->dma_req);
-	kfree(xpriv->pinfo);
-	free_netdev(netdev);
+  struct net_device *netdev = pci_get_drvdata(pdev);
+  struct onic_priv *xpriv;
+
+  if (!netdev) {
+    dev_err(&pdev->dev, "%s: netdev is NULL\n", __func__);
+    return;
+  }
+
+  xpriv = netdev_priv(netdev);
+  if (!xpriv) {
+    dev_err(&pdev->dev, "%s: xpriv is NULL\n", __func__);
+    return;
+  }
+
+  onic_qdma_rx_queue_release(xpriv, xpriv->pinfo->active_rx_queues);
+  onic_qdma_tx_queue_release(xpriv, xpriv->pinfo->active_tx_queues);
+  kfree(xpriv->tx_qstats);
+
+  pci_set_drvdata(pdev, NULL);
+  unregister_netdev(netdev);
+
+  onic_destroy_cdev(xpriv->onic_cdev_ptr);
+
+  onic_disable_cmac(xpriv);
+  if (xpriv->bar_base)
+    iounmap(xpriv->bar_base);
+  qdma_device_close(pdev, xpriv->dev_handle);
+  kmem_cache_destroy(xpriv->dma_req);
+  kfree(xpriv->pinfo);
+  free_netdev(netdev);
 }
 
 /* PCIe Driver */
 static struct pci_driver onic_pci_driver = {
-	.name = onic_drv_name,
-	.id_table = onic_pci_ids,
-	.probe = onic_pci_probe,
-	.remove = onic_pci_remove,
+  .name = onic_drv_name,
+  .id_table = onic_pci_ids,
+  .probe = onic_pci_probe,
+  .remove = onic_pci_remove,
 };
 
 /* This is the entry point of the NIC driver.
@@ -1333,22 +1500,19 @@ static struct pci_driver onic_pci_driver = {
  */
 static int __init onic_module_init(void)
 {
-	int err = 0;
-
-	/* Initialize QDMA Library */
-	err = libqdma_init(0, NULL);
-	if (err != 0) {
-		pr_err("%s: libqdma_init() failed\n", __func__);
-		return err;
-	}
-
-	err = pci_register_driver(&onic_pci_driver);
-	if (err < 0) {
-		pr_err("%s: PCI registration failed with status %d\n",
-		       __func__, err);
-	}
-
-	return err;
+  int err = 0;
+  /* Initialize QDMA Library */
+  err = libqdma_init(0, NULL);
+  if (err != 0) {
+    pr_err("%s: libqdma_init() failed\n", __func__);
+    return err;
+  }
+  err = pci_register_driver(&onic_pci_driver);
+  if (err < 0) {
+    pr_err("%s: PCI registration failed with status %d\n",
+           __func__, err);
+  }
+  return err;
 }
 
 /* This is the exit point of the NIC driver.
@@ -1356,13 +1520,15 @@ static int __init onic_module_init(void)
  */
 static void __exit onic_module_exit(void)
 {
-	pci_unregister_driver(&onic_pci_driver);
-	libqdma_exit();
+  pci_unregister_driver(&onic_pci_driver);
+  libqdma_exit();
 }
 
 module_init(onic_module_init);
 module_exit(onic_module_exit);
 
+MODULE_AUTHOR("Guanwen (Henry) Zhong");
+MODULE_AUTHOR("Burin Amornpaisannon");
 MODULE_AUTHOR("Hyunok Kim");
 MODULE_LICENSE("Dual BSD/GPL");
 MODULE_DESCRIPTION(DRV_VER);
